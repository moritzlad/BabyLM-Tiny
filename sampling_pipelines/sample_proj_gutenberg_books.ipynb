{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Gutenberg Book Sampling Pipeline\n",
    "\n",
    "This notebook processes Project Gutenberg books from the BabyLM corpus, fetches metadata from Gutendex API, and organizes books by genre for targeted sampling.\n",
    "\n",
    "## Features\n",
    "- Extract individual books from the corpus\n",
    "- Fetch metadata (author, title, subjects, bookshelves) from Gutendex\n",
    "- Organize books by literary genres\n",
    "- Generate genre-specific datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Book Extraction and Metadata Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fetch the text of the books from the Gutenberg dataset (too large to upload to GitHub)\n",
    "with open(f\"../datasets/train_100M/gutenberg.train\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_books = f.read()\n",
    "lines = all_books.split(\"\\n\")\n",
    "\n",
    "# split up the books\n",
    "texts = {}\n",
    "beginning_indices = []\n",
    "for i in range(len(lines)):\n",
    "    if lines[i].startswith(\"= = = \"):\n",
    "        beginning_indices.append(i)\n",
    "\n",
    "for i in range(len(beginning_indices) - 1):\n",
    "    gutenberg_id = lines[beginning_indices[i]][8:].split()[0]\n",
    "    if not gutenberg_id.isdigit():\n",
    "        print(\"Id-length: \", len(gutenberg_id), \"for id:\", gutenberg_id)\n",
    "        continue\n",
    "    text = \" \".join(lines[(beginning_indices[i] + 1):(beginning_indices[i + 1] - 1)])\n",
    "    texts[gutenberg_id] = text\n",
    "print(f\"Found {len(texts)} books in the Gutenberg dataset.\")\n",
    "print(\"Example book text:\", texts.get(\"52018\", \"\")[:500])  # Print first 500 characters of a sample book\n",
    "\n",
    "books_with_metadata = {} # id -> { 'text': str, 'author': str, 'title': str, 'subjects': list, 'bookshelves': list }\n",
    "\n",
    "# if metadata is locally available, load it\n",
    "if os.path.exists(\"../datasets/gutenberg/dataset_books_with_metadata.json\"):\n",
    "    with open(\"../datasets/gutenberg/dataset_books_with_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        books_with_metadata = json.load(f)\n",
    "    print(f\"Loaded {len(books_with_metadata)} books with metadata from local file.\")\n",
    "    print(\"Example book metadata:\", books_with_metadata.get(\"52018\", {}))\n",
    "\n",
    "# otherwise, fetch metadata from Gutendex\n",
    "else: \n",
    "    # Fetch metadata for each book from Gutendex\n",
    "    count = 0\n",
    "    for gutenberg_id, text in texts.items():\n",
    "        count += 1\n",
    "        if count % 50 == 0:\n",
    "            print(f\"Processing book ID {gutenberg_id}... ({count}/{len(texts)})\")\n",
    "        try:\n",
    "            response = requests.get(f\"https://gutendex.com/books/{gutenberg_id}\", timeout=30)\n",
    "            response.raise_for_status()\n",
    "            metadata = response.json()\n",
    "\n",
    "            authors = metadata.get(\"authors\", [])\n",
    "            if not authors:\n",
    "                author = \"Unknown\"\n",
    "            else:\n",
    "                author = authors[0].get(\"name\", \"Unknown\")\n",
    "            \n",
    "            books_with_metadata[gutenberg_id] = {\n",
    "                \n",
    "                'author': author,\n",
    "                'title': metadata[\"title\"],\n",
    "                'subjects': metadata[\"subjects\"],\n",
    "                'bookshelves': metadata[\"bookshelves\"]\n",
    "            }\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to get metadata for book {gutenberg_id}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing book {gutenberg_id}: {e}\")\n",
    "    with open(\"../datasets/gutenberg/dataset_books_with_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(books_with_metadata, f, ensure_ascii=False, indent=4)\n",
    "    print(len(books_with_metadata), \"books with metadata found.\")\n",
    "    print(\"Example book metadata:\", books_with_metadata.get(52018, {}))\n",
    "\n",
    "for gutenberg_id, book in books_with_metadata.items():\n",
    "    if gutenberg_id in texts:\n",
    "        book['text'] = texts[gutenberg_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bookshelves = set()\n",
    "all_subjects = set()\n",
    "bookshelve_counts = {}\n",
    "bookshelve_word_counts = {}\n",
    "subject_counts = {}\n",
    "subject_word_counts = {}\n",
    "for book in books_with_metadata.values():\n",
    "    word_count = len(book[\"text\"].split())\n",
    "    for bookshelve in book[\"bookshelves\"]:\n",
    "        all_bookshelves.add(bookshelve)\n",
    "        if bookshelve in bookshelve_counts:\n",
    "            bookshelve_counts[bookshelve] += 1\n",
    "            bookshelve_word_counts[bookshelve] += word_count\n",
    "        else:\n",
    "            bookshelve_counts[bookshelve] = 1\n",
    "            bookshelve_word_counts[bookshelve] = word_count\n",
    "    for subject in book[\"subjects\"]:\n",
    "        all_subjects.add(subject)\n",
    "        if subject in subject_counts:\n",
    "            subject_counts[subject] += 1\n",
    "            subject_word_counts[subject] += word_count\n",
    "        else:\n",
    "            subject_counts[subject] = 1\n",
    "            subject_word_counts[subject] = word_count\n",
    "\n",
    "print(f\"Total unique bookshelves: {len(all_bookshelves)}\")\n",
    "print(f\"Total unique subjects: {len(all_subjects)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bookshelf_list = sorted(list(all_bookshelves))\n",
    "subject_list = sorted(list(all_subjects))\n",
    "# print 10 most common bookshelves and subjects with their counts\n",
    "print(\"\\nMost common bookshelves:\")\n",
    "sorted_bookshelves = sorted(bookshelve_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for bookshelf, count in sorted_bookshelves[:10]:\n",
    "    print(f\"{bookshelf}: {count} books\")\n",
    "print(\"\\nMost common subjects:\")\n",
    "sorted_subjects = sorted(subject_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for subject, count in sorted_subjects[:10]:\n",
    "    print(f\"{subject}: {count} books\")\n",
    "\n",
    "# print 10 longest bookshelves and subjects with their total word counts\n",
    "print(\"\\nLongest bookshelves:\")\n",
    "sorted_bookshelves_by_length = sorted(bookshelve_word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for bookshelf, word_count in sorted_bookshelves_by_length[:10]:\n",
    "    print(f\"{bookshelf}: {word_count} words\")\n",
    "print(\"\\nLongest subjects:\")\n",
    "sorted_subjects_by_length = sorted(subject_word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "count = 1\n",
    "for subject, word_count in sorted_subjects_by_length:\n",
    "    if word_count < 500_000:\n",
    "        break\n",
    "    print(f\"{count}: {subject}: {word_count} words\")\n",
    "    count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metadata Analysis\n",
    "\n",
    "Analysis of book subjects and bookshelves to understand genre distribution and content availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from subjects to books\n",
    "subject_to_book_map = {}\n",
    "for subject in all_subjects:\n",
    "    subject_to_book_map[subject] = []\n",
    "for book_id, book in books_with_metadata.items():\n",
    "    for subject in book[\"subjects\"]:\n",
    "        subject_to_book_map[subject].append(book_id)\n",
    "\n",
    "# look at all pairs of subject, and check how many books they have in common\n",
    "subject_pairs = {}\n",
    "for i in range(len(subject_list)):\n",
    "    for j in range(i + 1, len(subject_list)):\n",
    "        subject1 = subject_list[i]\n",
    "        subject2 = subject_list[j]\n",
    "        common_books = set(subject_to_book_map[subject1]) & set(subject_to_book_map[subject2])\n",
    "        if common_books:\n",
    "            subject_pairs[(subject1, subject2)] = len(common_books)\n",
    "print(\"\\nMost common subject pairs:\")\n",
    "sorted_subject_pairs = sorted(subject_pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "for (subject1, subject2), count in sorted_subject_pairs[:10]:\n",
    "    print(f\"{subject1} & {subject2}: {count} common books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a list of tuples (gutenberg_id, name) a filename and a word limit\n",
    "# writes file with the books that have a word count less than the limit to \n",
    "# ./datasets/gutenberg/genres/filename.train\n",
    "def create_dataset_from_list(books, filename, word_limit):\n",
    "    if os.path.exists(f\"../datasets/gutenberg/genres/{filename}.train\"):\n",
    "        os.remove(f\"../datasets/gutenberg/genres/{filename}.train\")\n",
    "    word_count = 0\n",
    "    for gutenberg_id, name in books:\n",
    "        try:\n",
    "            response = requests.get(f\"https://www.gutenberg.org/cache/epub/{gutenberg_id}/pg{gutenberg_id}.txt\", timeout=30)\n",
    "            response.raise_for_status()\n",
    "            text = response.text\n",
    "            print(f\"Processing book {gutenberg_id} - {name}... ({len(text.split())} words)\")\n",
    "            # print(f\"First 100 characters: {text[:100]}\")\n",
    "            if word_count + len(text.split()) > word_limit:\n",
    "                print(f\"Word limit reached. Stopping.\")\n",
    "                # write the remaining number of words to hit the word limit exactly\n",
    "                text = \" \".join(text.split()[:word_limit - word_count])\n",
    "                with open(f\"../datasets/gutenberg/genres/{filename}.train\", \"a\", encoding=\"utf-8\") as f:\n",
    "                    f.write(f\"= = = {gutenberg_id} {name}\\n\")\n",
    "                    f.write(text + \"\\n\")\n",
    "                print(f\"Wrote {word_count + len(text.split())} words to {filename}.train with word limit {word_limit}.\")\n",
    "                break\n",
    "            word_count += len(text.split())\n",
    "            with open(f\"../datasets/gutenberg/genres/{filename}.train\", \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"= = = {gutenberg_id} {name}\\n\")\n",
    "                f.write(text + \"\\n\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to get book {gutenberg_id}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing book {gutenberg_id}: {e}\")\n",
    "    print(f\"Total words written to {filename}.train: {word_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Genre Dataset Creation\n",
    "\n",
    "Creates focused datasets for specific literary genres with 1M words for training and 200k words for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_fi_fantasy = [\n",
    "    (55, \"The Wonderful Wizard of Oz\"),\n",
    "    (36, \"The War of the Worlds\"),\n",
    "    (20000, \"Twenty Thousand Leagues Under the Sea\"),\n",
    "    (7477, \"The Book of Wonder\"),\n",
    "    (20782, \"Triplanetary\"),\n",
    "    (10002, \"The House on the Borderland\"),\n",
    "    (35, \"The Time Machine\"),\n",
    "    (18857, \"A Journey to the Centre of the Earth\"),\n",
    "    (1250, \"Anthem\"),\n",
    "    (159, \"The Island of Doctor Moreau\"),\n",
    "    (21279, \"2 B R 0 2 B\"),\n",
    "    (8395, \"The Gods of Pegāna\"),\n",
    "    (11, \"Alice's Adventures in Wonderland\"),   \n",
    "    (7506, \"The Steam Man of the Prairies\"),              \n",
    "    (289, \"The Night Land\"),                              \n",
    "    (1230, \"The Lost World\"),                            \n",
    "    (22615, \"The Princess Nobody: A Tale of Fairyland\"),  \n",
    "    (1505, \"The First Men in the Moon\"),                \n",
    "    (12163, \"The Sleeper Awakes\"),                      \n",
    "    (3479, \"The Metal Monster\"),                       \n",
    "    (17355, \"The Runaway Skyscraper\"),                  \n",
    "    (829, \"Gulliver's Travels\"),\n",
    "    (12, \"Through the Looking‑Glass\"),\n",
    "    (780, \"The War in the Air\"),    \n",
    "]\n",
    "\n",
    "sci_fi_fantasy_dev = [\n",
    "    (765, \"The Moon Pool\"),               \n",
    "    (1013, \"The First Men in the Moon\")\n",
    "    ]\n",
    "\n",
    "create_dataset_from_list(sci_fi_fantasy, \"1M_sci-fi_fantasy\", 1_000_000)\n",
    "create_dataset_from_list(sci_fi_fantasy_dev, \"1M_sci-fi_fantasy_dev\", 200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romance = [\n",
    "    (1342, \"Pride and Prejudice\"),                    # :contentReference[oaicite:0]{index=0}\n",
    "    (161, \"Sense and Sensibility\"),                   # :contentReference[oaicite:1]{index=1}\n",
    "    (158, \"Emma\"),                                    # :contentReference[oaicite:2]{index=2}\n",
    "    (105, \"Persuasion\"),                              # :contentReference[oaicite:3]{index=3}\n",
    "    (121, \"Northanger Abbey\"),                        # :contentReference[oaicite:4]{index=4}\n",
    "    (946, \"Lady Susan\"),                              # :contentReference[oaicite:5]{index=5}\n",
    "    (768, \"Wuthering Heights\"),                       # :contentReference[oaicite:7]{index=7}\n",
    "    (2413, \"Madame Bovary\"),                          # :contentReference[oaicite:9]{index=9}\n",
    "    (107, \"Far from the Madding Crowd\"),              # :contentReference[oaicite:10]{index=10}\n",
    "    (2641, \"A Room with a View\"),                     # :contentReference[oaicite:11]{index=11}\n",
    "    (541, \"The Age of Innocence\"),                    # :contentReference[oaicite:12]{index=12}\n",
    "    (284, \"The House of Mirth\"),                      # :contentReference[oaicite:13]{index=13}\n",
    "    (40619, \"Camilla; or, A Picture of Youth\"),       # :contentReference[oaicite:17]{index=17}\n",
    "    (6346, \"Cecilia; Or, Memoirs of an Heiress\"),     # :contentReference[oaicite:18]{index=18}\n",
    "    (498, \"Rebecca of Sunnybrook Farm\"),              # :contentReference[oaicite:19]{index=19}\n",
    "]\n",
    "romance_dev = [\n",
    "    (1399, \"Anna Karenina\"),  \n",
    "    (1260, \"Jane Eyre\"),    \n",
    "    (4517, \"Ethan Frome\"),            \n",
    "    (969, \"The Tenant of Wildfell Hall\"),\n",
    "    (6053, \"Evelina\"),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "create_dataset_from_list(romance, \"1M_romance\", 1_000_000)\n",
    "create_dataset_from_list(romance_dev, \"1M_romance_dev\", 200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_help_non_fiction = [\n",
    "    (935, \"Self-Help\"),  # :contentReference[oaicite:0]{index=0}\n",
    "    (14418, \"Thrift\"),  # :contentReference[oaicite:1]{index=1}\n",
    "    (2541, \"Character\"),  # :contentReference[oaicite:2]{index=2}\n",
    "    (4507, \"As a Man Thinketh\"),  # :contentReference[oaicite:3]{index=3}\n",
    "    (59844, \"The Science of Getting Rich\"),  # :contentReference[oaicite:4]{index=4}\n",
    "    (33917, \"The Science of Being Well\"),  # :contentReference[oaicite:5]{index=5}\n",
    "    (36898, \"Increasing Personal Efficiency\"),  # :contentReference[oaicite:6]{index=6}\n",
    "    (2274, \"How to Live on 24 Hours a Day\"),  # :contentReference[oaicite:7]{index=7}\n",
    "    (74178, \"Out from the Heart\"),  # :contentReference[oaicite:8]{index=8}\n",
    "    (74878, \"The Game of Life and How to Play It\"),  # :contentReference[oaicite:9]{index=9}\n",
    "    (147, \"Common Sense\"),  # :contentReference[oaicite:10]{index=10}\n",
    "    (20203, \"Autobiography of Benjamin Franklin\"),  # :contentReference[oaicite:11]{index=11}\n",
    "    (43855, \"Franklin's Way to Wealth; or, \\\"Poor Richard Improved\\\"\"),  # :contentReference[oaicite:12]{index=12}\n",
    "    (205, \"Walden, and On The Duty Of Civil Disobedience\"),  # :contentReference[oaicite:13]{index=13}\n",
    "    (3600, \"Essays of Michel de Montaigne — Complete\"),  # :contentReference[oaicite:14]{index=14}\n",
    "    (1232, \"The Prince\"),  # :contentReference[oaicite:15]{index=15}\n",
    "    (816, \"Democracy in America — Volume 2\"),  # :contentReference[oaicite:17]{index=17}\n",
    "]\n",
    "\n",
    "self_help_non_fiction_dev = [\n",
    "    (815, \"Democracy in America — Volume 1\"),  # :contentReference[oaicite:16]{index=16}\n",
    "    (3741, \"The American Crisis\"),  # :contentReference[oaicite:18]{index=18}\n",
    "]\n",
    "\n",
    "create_dataset_from_list(self_help_non_fiction, \"1M_self_help_non_fiction\", 1_000_000)\n",
    "create_dataset_from_list(self_help_non_fiction_dev, \"1M_self_help_non_fiction_dev\", 200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_english_drama_poetry = [\n",
    "    (1514,  \"A Midsummer Night's Dream\"),\n",
    "    (1523,  \"As You Like It\"),           \n",
    "    (1531,  \"Othello, the Moor of Venice\"),\n",
    "    (1524,  \"Hamlet, Prince of Denmark\"),  \n",
    "    (1533,  \"Macbeth\"),                    \n",
    "    (1532,  \"King Lear\"),                  \n",
    "    (1515,  \"The Merchant of Venice\"), \n",
    "    (1774,  \"Love's Labour's Lost\"), \n",
    "    (1103,  \"King Richard III\"),                       # :contentReference[oaicite:12]{index=12}\n",
    "    (1508,  \"The Taming of the Shrew\"),                # :contentReference[oaicite:13]{index=13}\n",
    "    (15272, \"The Faerie Queene, Book I\"),              # :contentReference[oaicite:14]{index=14}\n",
    "    (779,   \"The Tragical History of Doctor Faustus\"), # :contentReference[oaicite:15]{index=15}\n",
    "    (56375, \"Sir P.S.: His Astrophel and Stella\"),     # :contentReference[oaicite:16]{index=16}\n",
    "    (2232,  \"The Duchess of Malfi\"),                   # :contentReference[oaicite:17]{index=17}\n",
    "    (1094,  \"Tamburlaine the Great — Part 1\"),         # :contentReference[oaicite:18]{index=18}\n",
    "    (35330, \"The Spanish Tragedy\"),                    # :contentReference[oaicite:19]{index=19}\n",
    "    (1589,  \"Tamburlaine the Great — Part 2\"),         # :contentReference[oaicite:20]{index=20}\n",
    "    (4039,  \"Volpone; Or, The Fox\"),                   # :contentReference[oaicite:21]{index=21}\n",
    "    (4081,  \"The Alchemist\"),                          # :contentReference[oaicite:22]{index=22}\n",
    "    (3694,  \"Every Man in His Humour\"),                # :contentReference[oaicite:23]{index=23}\n",
    "    (1041, \"Shakespeare's Sonnets\"),                         # :contentReference[oaicite:0]{index=0}\n",
    "    (1045, \"Venus and Adonis\"),                              # :contentReference[oaicite:1]{index=1}\n",
    "    (1505, \"The Rape of Lucrece\"),                           # :contentReference[oaicite:2]{index=2}\n",
    "    (18781, \"Hero and Leander\"),                             # :contentReference[oaicite:3]{index=3}\n",
    "    (20288, \"Edward the Second\"),                            # :contentReference[oaicite:4]{index=4}\n",
    "    (901, \"The Jew of Malta\"),                               # :contentReference[oaicite:5]{index=5}\n",
    "    (4011, \"Epicoene; Or, The Silent Woman\"),                # :contentReference[oaicite:6]{index=6}\n",
    "    (12915, \"The White Devil\"),                              # :contentReference[oaicite:7]{index=7}\n",
    "    (20, \"Paradise Lost\"),                                   # :contentReference[oaicite:8]{index=8}\n",
    "    (58, \"Paradise Regained\"),                               # :contentReference[oaicite:9]{index=9}\n",
    "    (42607, \"The Shepheard's Calender\"),                     # :contentReference[oaicite:10]{index=10}\n",
    "    (72698, \"Spenser's Faerie Queene, Vol. 2: Books IV–VII\"), # :contentReference[oaicite:11]{index=11}\n",
    "]\n",
    "old_english_drama_poetry_dev = [\n",
    "    (1540, \"The Tempest\"),                     # EBook #1540 :contentReference[oaicite:0]{index=0}\n",
    "    (1526, \"Twelfth Night; Or, What You Will\"),# EBook #1526 :contentReference[oaicite:1]{index=1}\n",
    "    (1504, \"The Comedy of Errors\"),            # EBook #1504 :contentReference[oaicite:2]{index=2}\n",
    "    (1513, \"Romeo and Juliet\"),                # EBook #1513 :contentReference[oaicite:3]{index=3}\n",
    "    (1522, \"Julius Caesar\"),                   # EBook #1522 :contentReference[oaicite:4]{index=4}\n",
    "    (1539, \"The Winter's Tale\"),               # EBook #1539 :contentReference[oaicite:5]{index=5}\n",
    "    (1107, \"The Taming of the Shrew\"),         # EBook #1107 :contentReference[oaicite:6]{index=6}\n",
    "    (1509, \"The Two Gentlemen of Verona\"),     # EBook #1509 :contentReference[oaicite:7]{index=7}\n",
    "    (1519, \"Much Ado About Nothing\"),          # EBook #1519 :contentReference[oaicite:8]{index=8}\n",
    "    (2237, \"The Merry Wives of Windsor\"),      # EBook #2237 :contentReference[oaicite:9]{index=9}\n",
    "]\n",
    "\n",
    "create_dataset_from_list(old_english_drama_poetry, \"1M_old_english_drama_poetry\", 1_000_000)\n",
    "create_dataset_from_list(old_english_drama_poetry_dev, \"1M_old_english_drama_poetry_dev\", 200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_books = [\n",
    "    (1661, \"The Adventures of Sherlock Holmes\"),          # Conan Doyle’s famed short stories :contentReference[oaicite:0]{index=0}\n",
    "    (244, \"A Study in Scarlet\"),                          # Holmes’s first novel :contentReference[oaicite:1]{index=1}\n",
    "    (3070, \"The Hound of the Baskervilles\"),              # Classic Holmes thriller :contentReference[oaicite:2]{index=2}\n",
    "    (863, \"The Mysterious Affair at Styles\"),             # Christie’s debut detective novel :contentReference[oaicite:4]{index=4}\n",
    "    (2097, \"The Sign of the Four\"),                       # Holmes mystery sequel :contentReference[oaicite:5]{index=5}\n",
    "    (1685, \"The Mystery of the Yellow Room\"),             # Ingénious locked-room puzzle :contentReference[oaicite:6]{index=6}\n",
    "    (564, \"The Mystery of Edwin Drood\"),                   # Dickens’s final (unfinished) mystery :contentReference[oaicite:8]{index=8}\n",
    "    (1155, \"The Secret Adversary\"),                       # Christie’s Tommy & Tuppence spy yarn :contentReference[oaicite:9]{index=9}\n",
    "    (558, \"The Thirty-Nine Steps\"),                       # Buchan’s espionage thriller :contentReference[oaicite:10]{index=10}\n",
    "    (2147, \"The Mystery of Marie Rogêt\"),                  # Poe’s true-crime inspired tale :contentReference[oaicite:12]{index=12}\n",
    "    (220, \"The Secret Sharer\"),                            # Conrad’s psychological thriller :contentReference[oaicite:13]{index=13}\n",
    "    (34973, \"The Spy of the Rebellion\"),                   # Pinkerton’s Civil War espionage memoir :contentReference[oaicite:14]{index=14}\n",
    "    (39940, \"Ashton Kirk, Secret Agent\"),                  # Early pulp spy adventures :contentReference[oaicite:15]{index=15}\n",
    "    (155, \"The Moonstone\"),                               # Early English detective novel :contentReference[oaicite:3]{index=3}\n",
    "    (583, \"The Woman in White\"),                          # Collins’s suspenseful thriller :contentReference[oaicite:7]{index=7}\n",
    "    (4919, \"The Murder on the Links\"),                    # Poirot’s second case :contentReference[oaicite:11]{index=11}\n",
    "\n",
    "]\n",
    "mystery_books_dev = [\n",
    "    (38131, \"On Secret Service\"),                          # Taft’s real-life government cases :contentReference[oaicite:16]{index=16}\n",
    "    (48823, \"Spies and Secret Service\"),                   # Le Queux’s WWI espionage tales :contentReference[oaicite:17]{index=17}\n",
    "    (61069, \"German Spies in England: An Exposure\"),       # Le Queux’s exposé of wartime espionage :contentReference[oaicite:18]{index=18}\n",
    "    (41186, \"Sant of the Secret Service: Some Revelations of Spies and Spying\"),  # Le Queux on WWI spycraft :contentReference[oaicite:19]{index=19}\n",
    "]\n",
    "\n",
    "create_dataset_from_list(mystery_books, \"1M_mystery_books\", 1_000_000)\n",
    "create_dataset_from_list(mystery_books_dev, \"1M_mystery_books_dev\", 200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youth_and_ya_gutenberg = [\n",
    "    (11,    \"Alice's Adventures in Wonderland\"),\n",
    "    (74,    \"The Adventures of Tom Sawyer\"),\n",
    "    (76,    \"Adventures of Huckleberry Finn\"),\n",
    "    (16,    \"Peter Pan\"),\n",
    "    (514,   \"Little Women\"),\n",
    "    (1448,  \"Heidi\"),\n",
    "    (45,    \"Anne of Green Gables\"),\n",
    "    (17396, \"The Secret Garden\"),\n",
    "    (120,   \"Treasure Island\"),\n",
    "    (271,   \"Black Beauty\"),\n",
    "    (55,    \"The Wonderful Wizard of Oz\"),\n",
    "    (1450,  \"Pollyanna\"),\n",
    "    (146,   \"A Little Princess\"),\n",
    "\n",
    "]\n",
    "\n",
    "youth_and_ya_gutenberg_dev = [\n",
    "    (236,   \"The Jungle Book\"),\n",
    "    (1874,  \"The Railway Children\"),\n",
    "    (3836,  \"Swiss Family Robinson\"),\n",
    "    (17314, \"Five Children and It\"),\n",
    "    (1480,  \"Tom Brown's School Days\"),\n",
    "    (421,   \"Kidnapped\"),\n",
    "    (1018,  \"The Water-Babies\"),\n",
    "]\n",
    "create_dataset_from_list(youth_and_ya_gutenberg, \"1M_youth_and_ya_gutenberg\", 1_000_000)\n",
    "create_dataset_from_list(youth_and_ya_gutenberg_dev, \"1M_youth_and_ya_gutenberg_dev\", 200_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyLM-100M Dataset Sampling Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides sampling utilities for creating smaller, focused datasets from the BabyLM-100M corpus while preserving linguistic diversity.\n",
    "\n",
    "### Dataset Components\n",
    "- **BNC Spoken**: British National Corpus spoken data\n",
    "- **CHILDES**: Child language transcripts  \n",
    "- **Gutenberg**: Project Gutenberg literature\n",
    "- **OpenSubtitles**: Movie/TV subtitles\n",
    "- **SimpleWiki**: Simplified Wikipedia\n",
    "- **Switchboard**: Telephone conversations\n",
    "\n",
    "### Quick Start\n",
    "```python\n",
    "# Mixed dataset (1M words)\n",
    "sample_proportions(\"mixed_1M\", 1_000_000, \n",
    "                  bnc_spoken=0.2, childes=0.2, gutenberg=0.2, \n",
    "                  open_subtitles=0.2, simple_wiki=0.2)\n",
    "\n",
    "# Literature sampling (50% of books)\n",
    "sample_percentage_of_books(0.5, 1_000_000, \"gutenberg_50pct\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Core Sampling Functions\n",
    "\n",
    "**Sampling Strategy**: Uses 10,000-word snippets to preserve context while ensuring diverse coverage.\n",
    "\n",
    "| Function | Purpose |\n",
    "|----------|---------|\n",
    "| `sample_from_single_file()` | Sample from individual corpus files |\n",
    "| `sample_proportions()` | Create mixed datasets with specified proportions |\n",
    "| `sample_percentage_of_books()` | Sample percentage of Gutenberg books |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "SNIPPET_SIZE = 10_000\n",
    "\n",
    "def sample_from_single_file(file_name, target_words, target_folder):\n",
    "    with open(f\"../datasets/BabyLM_dataset/train_100M/{file_name}.train\", \"r\", encoding=\"utf-8\") as f:\n",
    "        words = f.read().split()\n",
    "    total_words = len(words)\n",
    "    num_snippets = int(1.2 * target_words) // SNIPPET_SIZE\n",
    "    if (total_words > target_words + int(0.2 * target_words)):\n",
    "        max_start = total_words - SNIPPET_SIZE\n",
    "        starts = random.sample(range(max_start), num_snippets)\n",
    "\n",
    "        snippets = [words[start:start + SNIPPET_SIZE] for start in starts]\n",
    "\n",
    "        sampled_words = [word for snippet in snippets for word in snippet]\n",
    "\n",
    "        train_words = sampled_words[:target_words]\n",
    "        dev_words = sampled_words[target_words:]\n",
    "\n",
    "        # Fix: Write only train words to main file\n",
    "        with open(f\"../datasets/BabyLM_dataset/{target_folder}/{file_name}.train\", \"w+\", encoding=\"utf-8\") as f:\n",
    "            f.write(\" \".join(train_words))  # Changed from sampled_words to train_words\n",
    "        with open(f\"../datasets/BabyLM_dataset/{target_folder}/{file_name}_dev.train\", \"w+\", encoding=\"utf-8\") as f:\n",
    "            f.write(\" \".join(dev_words))\n",
    "    else: \n",
    "        print(f\"File {file_name} has only {total_words} words, not enough to sample {target_words} words.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_proportions (output_name, no_words, bnc_spoken, childes, gutenberg, open_subtitles, simple_wiki, switchboard):\n",
    "    # if bnc_spoken + childes + gutenberg + open_subtitles + simple_wiki + switchboard != 1:\n",
    "    #     raise ValueError(\"Proportions must sum to 1.\")\n",
    "\n",
    "    files = [\"bnc_spoken.train\", \"childes.train\", \"gutenberg.train\", \"open_subtitles.train\", \"simple_wiki.train\", \"switchboard.train\"]\n",
    "    proportions = [bnc_spoken, childes, gutenberg, open_subtitles, simple_wiki, switchboard]\n",
    "\n",
    "    train_words = []\n",
    "    dev_words = []\n",
    "    \n",
    "    for i in range(len(files)):\n",
    "        file = files[i]\n",
    "        total_words_needed = int((1.2 * no_words) * proportions[i])\n",
    "        train_words_needed = int(no_words * proportions[i])\n",
    "        dev_words_needed = total_words_needed - train_words_needed\n",
    "        \n",
    "        if total_words_needed == 0:\n",
    "            continue\n",
    "            \n",
    "        with open(f\"../datasets/BabyLM_dataset/train_100M/{file}\", \"r\", encoding=\"utf-8\") as f:\n",
    "            words = f.read().split()\n",
    "        total_words = len(words)\n",
    "\n",
    "        if total_words < total_words_needed:\n",
    "            print(f\"File {file} has only {total_words} words, not enough to sample {total_words_needed} words.\")\n",
    "            continue\n",
    "\n",
    "        # Calculate snippets needed for this file specificallyNUM_SNIPnum_snippetsPETS\n",
    "        snippets_needed = (total_words_needed + SNIPPET_SIZE - 1) // SNIPPET_SIZE  # Ceiling division\n",
    "        max_start = total_words - SNIPPET_SIZE\n",
    "        starts = random.sample(range(max_start), min(snippets_needed, max_start))\n",
    "        snippets = [words[start:start + SNIPPET_SIZE] for start in starts]\n",
    "        file_words = [word for snippet in snippets for word in snippet][:total_words_needed]\n",
    "        \n",
    "        # Split this file's words into train and dev proportionally\n",
    "        file_train_words = file_words[:train_words_needed]\n",
    "        file_dev_words = file_words[train_words_needed:train_words_needed + dev_words_needed]\n",
    "        \n",
    "        train_words.extend(file_train_words)\n",
    "        dev_words.extend(file_dev_words)\n",
    "    \n",
    "    print(f\"Train words: {len(train_words)}\")\n",
    "    print(f\"Dev words: {len(dev_words)}\")\n",
    "    with open(f\"../datasets/BabyLM_dataset/{output_name}.train\", \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(\" \".join(train_words))\n",
    "    with open(f\"../datasets/BabyLM_dataset/{output_name}_dev.train\", \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(\" \".join(dev_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 1212910 words from 107 books.\n",
      "Train text length: 1000000 words.\n",
      "Dev text length: 200000 words.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/BabyLM_dataset/books_context/gutenberg_1M_25pct_books.train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m../datasets/BabyLM_dataset/books_context/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_dev.train\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     34\u001b[39m         f.write(dev_text)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43msample_percentage_of_books\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1_000_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgutenberg_1M_25pct_books\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m sample_percentage_of_books(\u001b[32m0.5\u001b[39m, \u001b[32m1_000_000\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgutenberg_1M_50pct_books\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m sample_percentage_of_books(\u001b[32m0.75\u001b[39m, \u001b[32m1_000_000\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgutenberg_1M_75pct_books\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36msample_percentage_of_books\u001b[39m\u001b[34m(percentage, target_words, filename)\u001b[39m\n\u001b[32m     28\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDev text length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dev_text.split())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m words.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../datasets/BabyLM_dataset/books_context/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     32\u001b[39m     f.write(train_text)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m../datasets/BabyLM_dataset/books_context/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_dev.train\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/06_SS2025/Praktikum_NLP/BabyLM-Tiny/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:327\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../datasets/BabyLM_dataset/books_context/gutenberg_1M_25pct_books.train'"
     ]
    }
   ],
   "source": [
    "def sample_percentage_of_books(percentage, target_words, filename):\n",
    "    \"\"\"Sample a percentage of books from the Gutenberg corpus\n",
    "    \n",
    "    Args:\n",
    "        percentage: Fraction of books to sample (0.0 to 1.0)\n",
    "        target_words: Number of words for training set\n",
    "        filename: Output filename prefix\n",
    "    \"\"\"\n",
    "    with open(f\"../datasets/BabyLM_dataset/train_100M/gutenberg.train\", \"r\", encoding=\"utf-8\") as f:\n",
    "        all_books = f.read()\n",
    "    lines = all_books.split(\"\\n\")\n",
    "\n",
    "    # Find book boundaries\n",
    "    beginning_indices = []\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].startswith(\"= = = \"):\n",
    "            beginning_indices.append(i)\n",
    "    \n",
    "    target_with_dev = int(1.2 * target_words)\n",
    "    \n",
    "    # Sample the specified percentage of books\n",
    "    text = \"\"\n",
    "    total_words = 0\n",
    "    books_used = 0\n",
    "    \n",
    "    for i in range(int(len(beginning_indices) * percentage)):\n",
    "        if i + 1 >= len(beginning_indices):\n",
    "            break\n",
    "            \n",
    "        number_of_lines = beginning_indices[i + 1] - beginning_indices[i] - 1\n",
    "        last_index = beginning_indices[i] + int(percentage * number_of_lines)\n",
    "        book_text = \" \".join(lines[(beginning_indices[i] + 1):last_index])\n",
    "        total_words += len(book_text.split())\n",
    "        text += book_text + \" \"\n",
    "        books_used += 1\n",
    "        \n",
    "        if total_words >= target_with_dev:\n",
    "            print(f\"Sampled {total_words} words from {i + 1} books.\")\n",
    "            text_words = text.split()\n",
    "            train_text = \" \".join(text_words[:target_words])\n",
    "            print(f\"Train text length: {len(train_text.split())} words.\")\n",
    "            dev_text = \" \".join(text_words[target_words:target_with_dev])\n",
    "            print(f\"Dev text length: {len(dev_text.split())} words.\")\n",
    "            break\n",
    "\n",
    "    with open(f\"../datasets/BabyLM_dataset/books_context/{filename}.train\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(train_text)\n",
    "    with open(f\"../datasets/BabyLM_dataset/books_context/{filename}_dev.train\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(dev_text)\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# sample_percentage_of_books(0.25, 1_000_000, \"gutenberg_1M_25pct_books\")\n",
    "# sample_percentage_of_books(0.5, 1_000_000, \"gutenberg_1M_50pct_books\")\n",
    "# sample_percentage_of_books(0.75, 1_000_000, \"gutenberg_1M_75pct_books\")\n",
    "# sample_percentage_of_books(1.0, 1_000_000, \"gutenberg_1M_100pct_books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Book Sampling & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Gutenberg book dataset...\n",
      "Total number of books in dataset: 563\n",
      "Average words per book: 46834\n",
      "Total words in all books: 26,367,293\n",
      "25% sampling uses approximately 140 books\n",
      "  - Total words available from 25% sampling: 1,863,965\n",
      "50% sampling uses approximately 281 books\n",
      "  - Total words available from 50% sampling: 6,926,689\n",
      "75% sampling uses approximately 422 books\n",
      "  - Total words available from 75% sampling: 15,171,320\n",
      "100% sampling uses approximately 563 books\n",
      "  - Total words available from 100% sampling: 26,367,293\n"
     ]
    }
   ],
   "source": [
    "def analyze_book_dataset():\n",
    "    \"\"\"Analyze the Gutenberg book dataset statistics\"\"\"\n",
    "    print(\"Analyzing Gutenberg book dataset...\")\n",
    "    \n",
    "    with open(f\"../datasets/BabyLM_dataset/train_100M/gutenberg.train\", \"r\", encoding=\"utf-8\") as f:\n",
    "        all_books = f.read()\n",
    "    \n",
    "    lines = all_books.split(\"\\n\")\n",
    "    \n",
    "    # Find book boundaries\n",
    "    beginning_indices = []\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].startswith(\"= = = \"):\n",
    "            beginning_indices.append(i)\n",
    "    \n",
    "    # Add the end of the file as the last boundary\n",
    "    beginning_indices.append(len(lines))\n",
    "    \n",
    "    total_books = len(beginning_indices) - 1  # Subtract 1 because we added the end index\n",
    "    print(f\"Total number of books in dataset: {total_books}\")\n",
    "    \n",
    "    # Calculate word count for each book\n",
    "    book_word_counts = []\n",
    "    total_words_all_books = 0\n",
    "    \n",
    "    for i in range(total_books):\n",
    "        start_line = beginning_indices[i] + 1  # Skip the header line\n",
    "        end_line = beginning_indices[i + 1]\n",
    "        \n",
    "        book_text = \" \".join(lines[start_line:end_line])\n",
    "        word_count = len(book_text.split())\n",
    "        book_word_counts.append(word_count)\n",
    "        total_words_all_books += word_count\n",
    "    \n",
    "    # Calculate statistics\n",
    "    average_words_per_book = total_words_all_books / total_books\n",
    "    print(f\"Average words per book: {average_words_per_book:.0f}\")\n",
    "    print(f\"Total words in all books: {total_words_all_books:,}\")\n",
    "    \n",
    "    # Calculate number of books for each percentage\n",
    "    percentages = [0.25, 0.5, 0.75, 1.0]\n",
    "    for pct in percentages:\n",
    "        num_books = int(total_books * pct)\n",
    "        print(f\"\\n{pct*100:.0f}% sampling uses approximately {num_books} books\")\n",
    "        \n",
    "        # Calculate actual words available\n",
    "        words_used = 0\n",
    "        for i in range(num_books):\n",
    "            start_line = beginning_indices[i] + 1\n",
    "            end_line = beginning_indices[i + 1]\n",
    "            number_of_lines = end_line - start_line\n",
    "            lines_to_use = int(pct * number_of_lines)\n",
    "            book_text = \" \".join(lines[start_line:(start_line + lines_to_use)])\n",
    "            words_used += len(book_text.split())\n",
    "        \n",
    "        print(f\"  Total words available: {words_used:,}\")\n",
    "    \n",
    "    return {\n",
    "        'total_books': total_books,\n",
    "        'average_words_per_book': average_words_per_book,\n",
    "        'total_words': total_words_all_books,\n",
    "        'book_word_counts': book_word_counts\n",
    "    }\n",
    "\n",
    "# Run the analysis\n",
    "stats = analyze_book_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quantifier Analysis\n",
    "\n",
    "Analysis of quantifier usage patterns across different text genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting quantifiers in Gutenberg genre datasets...\n",
      "============================================================\n",
      "Found 6 dataset files:\n",
      "  - 1M_mystery_books.train\n",
      "  - 1M_old_english_drama_poetry.train\n",
      "  - 1M_sci-fi_fantasy.train\n",
      "  - 1M_self_help_non_fiction.train\n",
      "  - 1M_romance.train\n",
      "  - 1M_youth_and_ya_gutenberg.train\n",
      "\n",
      "============================================================\n",
      "\n",
      "Processing 1M_mystery_books.train...\n",
      "  Total quantifiers found: 39,282 (Genre: Mystery)\n",
      "Processing 1M_old_english_drama_poetry.train...\n",
      "  Total quantifiers found: 39,282 (Genre: Mystery)\n",
      "Processing 1M_old_english_drama_poetry.train...\n",
      "  Total quantifiers found: 32,558 (Genre: Old English Drama/Poetry)\n",
      "Processing 1M_sci-fi_fantasy.train...\n",
      "  Total quantifiers found: 32,558 (Genre: Old English Drama/Poetry)\n",
      "Processing 1M_sci-fi_fantasy.train...\n",
      "  Total quantifiers found: 42,419 (Genre: Sci-Fi/Fantasy)\n",
      "Processing 1M_self_help_non_fiction.train...\n",
      "  Total quantifiers found: 42,419 (Genre: Sci-Fi/Fantasy)\n",
      "Processing 1M_self_help_non_fiction.train...\n",
      "  Total quantifiers found: 43,521 (Genre: Self-Help/Non-Fiction)\n",
      "Processing 1M_romance.train...\n",
      "  Total quantifiers found: 43,521 (Genre: Self-Help/Non-Fiction)\n",
      "Processing 1M_romance.train...\n",
      "  Total quantifiers found: 47,528 (Genre: Romance)\n",
      "Processing 1M_youth_and_ya_gutenberg.train...\n",
      "  Total quantifiers found: 47,528 (Genre: Romance)\n",
      "Processing 1M_youth_and_ya_gutenberg.train...\n",
      "  Total quantifiers found: 46,522 (Genre: Youth/YA)\n",
      "\n",
      "============================================================\n",
      "SUMMARY RESULTS\n",
      "============================================================\n",
      "\n",
      "Quantifier counts across all genre datasets:\n",
      "--------------------------------------------------\n",
      "all            :   27,813\n",
      "no             :   20,095\n",
      "more           :   12,603\n",
      "any            :   12,318\n",
      "about          :   10,520\n",
      "some           :   10,509\n",
      "other          :    9,620\n",
      "little         :    9,405\n",
      "such           :    8,593\n",
      "much           :    8,008\n",
      "never          :    7,431\n",
      "over           :    7,078\n",
      "most           :    6,409\n",
      "every          :    5,543\n",
      "nothing        :    5,142\n",
      "many           :    4,672\n",
      "once           :    4,088\n",
      "under          :    4,058\n",
      "another        :    3,975\n",
      "always         :    3,322\n",
      "something      :    3,246\n",
      "a little       :    3,153\n",
      "both           :    3,063\n",
      "enough         :    2,811\n",
      "half           :    2,789\n",
      "each           :    2,774\n",
      "few            :    2,605\n",
      "anything       :    2,379\n",
      "whole          :    2,378\n",
      "almost         :    2,349\n",
      "others         :    2,240\n",
      "often          :    1,892\n",
      "rest           :    1,859\n",
      "less           :    1,857\n",
      "a few          :    1,817\n",
      "certain        :    1,740\n",
      "more than      :    1,639\n",
      "several        :    1,622\n",
      "above          :    1,601\n",
      "either         :    1,522\n",
      "everything     :    1,487\n",
      "sometimes      :    1,346\n",
      "hundred        :    1,328\n",
      "none           :    1,284\n",
      "neither        :    1,237\n",
      "thousand       :    1,233\n",
      "around         :    1,178\n",
      "ought          :    1,134\n",
      "nearly         :    1,050\n",
      "below          :    1,044\n",
      "no one         :      961\n",
      "different      :      934\n",
      "at least       :      921\n",
      "anyone         :      852\n",
      "nobody         :      659\n",
      "everybody      :      565\n",
      "anybody        :      453\n",
      "various        :      453\n",
      "twice          :      417\n",
      "anywhere       :      399\n",
      "dozen          :      354\n",
      "couple         :      352\n",
      "entire         :      305\n",
      "many a         :      303\n",
      "somebody       :      302\n",
      "less than      :      302\n",
      "a number of    :      298\n",
      "everywhere     :      294\n",
      "plenty         :      290\n",
      "somewhere      :      285\n",
      "a lot of       :      275\n",
      "seldom         :      274\n",
      "everyone       :      211\n",
      "numerous       :      198\n",
      "someone        :      188\n",
      "host           :      188\n",
      "a great deal of:      174\n",
      "score          :      160\n",
      "multitude      :      137\n",
      "no more than   :      127\n",
      "rarely         :      112\n",
      "aught          :      109\n",
      "bulk           :      102\n",
      "nowhere        :      100\n",
      "majority       :       98\n",
      "naught         :       96\n",
      "thrice         :       92\n",
      "countless      :       78\n",
      "fewer          :       73\n",
      "lots of        :       68\n",
      "divers         :       53\n",
      "roughly        :       49\n",
      "whit           :       49\n",
      "sundry         :       47\n",
      "no less than   :       41\n",
      "manifold       :       39\n",
      "at most        :       25\n",
      "myriad         :       25\n",
      "minority       :       24\n",
      "fewer than     :       22\n",
      "legion         :       21\n",
      "loads of       :       11\n",
      "approximately  :        5\n",
      "nary           :        1\n",
      "--------------------------------------------------\n",
      "TOTAL          :  251,830\n",
      "\n",
      "\n",
      "Quantifier counts by GENRE:\n",
      "============================================================\n",
      "Romance                  :   47,528\n",
      "  └─ Files:               1M_romance.train\n",
      "\n",
      "Youth/YA                 :   46,522\n",
      "  └─ Files:               1M_youth_and_ya_gutenberg.train\n",
      "\n",
      "Self-Help/Non-Fiction    :   43,521\n",
      "  └─ Files:               1M_self_help_non_fiction.train\n",
      "\n",
      "Sci-Fi/Fantasy           :   42,419\n",
      "  └─ Files:               1M_sci-fi_fantasy.train\n",
      "\n",
      "Mystery                  :   39,282\n",
      "  └─ Files:               1M_mystery_books.train\n",
      "\n",
      "Old English Drama/Poetry :   32,558\n",
      "  └─ Files:               1M_old_english_drama_poetry.train\n",
      "\n",
      "============================================================\n",
      "GRAND TOTAL: 251,830\n",
      "\n",
      "Detailed breakdown by file (top 5 quantifiers):\n",
      "--------------------------------------------------------------------------------\n",
      "File                                   all          no        more         any       about       Total\n",
      "--------------------------------------------------------------------------------\n",
      "1M_mystery_books.train               3,627       3,689       1,722       2,014       2,006      39,282\n",
      "1M_old_english_drama_poetry.train       5,138       3,429       2,100       1,818         768      32,558\n",
      "1M_romance.train                     4,709       3,997       2,559       2,534       1,539      47,528\n",
      "1M_sci-fi_fantasy.train              4,627       2,961       1,721       2,026       2,248      42,419\n",
      "1M_self_help_non_fiction.train       4,406       2,799       2,757       2,175       1,112      43,521\n",
      "1M_youth_and_ya_gutenberg.train       5,306       3,220       1,744       1,751       2,847      46,522\n",
      "  Total quantifiers found: 46,522 (Genre: Youth/YA)\n",
      "\n",
      "============================================================\n",
      "SUMMARY RESULTS\n",
      "============================================================\n",
      "\n",
      "Quantifier counts across all genre datasets:\n",
      "--------------------------------------------------\n",
      "all            :   27,813\n",
      "no             :   20,095\n",
      "more           :   12,603\n",
      "any            :   12,318\n",
      "about          :   10,520\n",
      "some           :   10,509\n",
      "other          :    9,620\n",
      "little         :    9,405\n",
      "such           :    8,593\n",
      "much           :    8,008\n",
      "never          :    7,431\n",
      "over           :    7,078\n",
      "most           :    6,409\n",
      "every          :    5,543\n",
      "nothing        :    5,142\n",
      "many           :    4,672\n",
      "once           :    4,088\n",
      "under          :    4,058\n",
      "another        :    3,975\n",
      "always         :    3,322\n",
      "something      :    3,246\n",
      "a little       :    3,153\n",
      "both           :    3,063\n",
      "enough         :    2,811\n",
      "half           :    2,789\n",
      "each           :    2,774\n",
      "few            :    2,605\n",
      "anything       :    2,379\n",
      "whole          :    2,378\n",
      "almost         :    2,349\n",
      "others         :    2,240\n",
      "often          :    1,892\n",
      "rest           :    1,859\n",
      "less           :    1,857\n",
      "a few          :    1,817\n",
      "certain        :    1,740\n",
      "more than      :    1,639\n",
      "several        :    1,622\n",
      "above          :    1,601\n",
      "either         :    1,522\n",
      "everything     :    1,487\n",
      "sometimes      :    1,346\n",
      "hundred        :    1,328\n",
      "none           :    1,284\n",
      "neither        :    1,237\n",
      "thousand       :    1,233\n",
      "around         :    1,178\n",
      "ought          :    1,134\n",
      "nearly         :    1,050\n",
      "below          :    1,044\n",
      "no one         :      961\n",
      "different      :      934\n",
      "at least       :      921\n",
      "anyone         :      852\n",
      "nobody         :      659\n",
      "everybody      :      565\n",
      "anybody        :      453\n",
      "various        :      453\n",
      "twice          :      417\n",
      "anywhere       :      399\n",
      "dozen          :      354\n",
      "couple         :      352\n",
      "entire         :      305\n",
      "many a         :      303\n",
      "somebody       :      302\n",
      "less than      :      302\n",
      "a number of    :      298\n",
      "everywhere     :      294\n",
      "plenty         :      290\n",
      "somewhere      :      285\n",
      "a lot of       :      275\n",
      "seldom         :      274\n",
      "everyone       :      211\n",
      "numerous       :      198\n",
      "someone        :      188\n",
      "host           :      188\n",
      "a great deal of:      174\n",
      "score          :      160\n",
      "multitude      :      137\n",
      "no more than   :      127\n",
      "rarely         :      112\n",
      "aught          :      109\n",
      "bulk           :      102\n",
      "nowhere        :      100\n",
      "majority       :       98\n",
      "naught         :       96\n",
      "thrice         :       92\n",
      "countless      :       78\n",
      "fewer          :       73\n",
      "lots of        :       68\n",
      "divers         :       53\n",
      "roughly        :       49\n",
      "whit           :       49\n",
      "sundry         :       47\n",
      "no less than   :       41\n",
      "manifold       :       39\n",
      "at most        :       25\n",
      "myriad         :       25\n",
      "minority       :       24\n",
      "fewer than     :       22\n",
      "legion         :       21\n",
      "loads of       :       11\n",
      "approximately  :        5\n",
      "nary           :        1\n",
      "--------------------------------------------------\n",
      "TOTAL          :  251,830\n",
      "\n",
      "\n",
      "Quantifier counts by GENRE:\n",
      "============================================================\n",
      "Romance                  :   47,528\n",
      "  └─ Files:               1M_romance.train\n",
      "\n",
      "Youth/YA                 :   46,522\n",
      "  └─ Files:               1M_youth_and_ya_gutenberg.train\n",
      "\n",
      "Self-Help/Non-Fiction    :   43,521\n",
      "  └─ Files:               1M_self_help_non_fiction.train\n",
      "\n",
      "Sci-Fi/Fantasy           :   42,419\n",
      "  └─ Files:               1M_sci-fi_fantasy.train\n",
      "\n",
      "Mystery                  :   39,282\n",
      "  └─ Files:               1M_mystery_books.train\n",
      "\n",
      "Old English Drama/Poetry :   32,558\n",
      "  └─ Files:               1M_old_english_drama_poetry.train\n",
      "\n",
      "============================================================\n",
      "GRAND TOTAL: 251,830\n",
      "\n",
      "Detailed breakdown by file (top 5 quantifiers):\n",
      "--------------------------------------------------------------------------------\n",
      "File                                   all          no        more         any       about       Total\n",
      "--------------------------------------------------------------------------------\n",
      "1M_mystery_books.train               3,627       3,689       1,722       2,014       2,006      39,282\n",
      "1M_old_english_drama_poetry.train       5,138       3,429       2,100       1,818         768      32,558\n",
      "1M_romance.train                     4,709       3,997       2,559       2,534       1,539      47,528\n",
      "1M_sci-fi_fantasy.train              4,627       2,961       1,721       2,026       2,248      42,419\n",
      "1M_self_help_non_fiction.train       4,406       2,799       2,757       2,175       1,112      43,521\n",
      "1M_youth_and_ya_gutenberg.train       5,306       3,220       1,744       1,751       2,847      46,522\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_quantifiers_in_gutenberg_genres():\n",
    "    \"\"\"Count occurrences of quantifiers in all Gutenberg genre datasets\"\"\"\n",
    "    \n",
    "    quantifiers = [\n",
    "        # Basic universal quantifiers\n",
    "        \"all\", \"every\", \"each\", \"everyone\", \"everybody\", \"everything\", \"everywhere\",\n",
    "        # Existential quantifiers\n",
    "        \"some\", \"any\", \"someone\", \"somebody\", \"something\", \"somewhere\", \n",
    "        \"anyone\", \"anybody\", \"anything\", \"anywhere\",\n",
    "        # Negative quantifiers\n",
    "        \"no\", \"none\", \"nothing\", \"nobody\", \"no one\", \"nowhere\", \"neither\", \"never\",\n",
    "        # Numerical/proportional quantifiers\n",
    "        \"most\", \"many\", \"much\", \"few\", \"a few\", \"little\", \"a little\", \"several\",\n",
    "        \"numerous\", \"countless\",\n",
    "        # Old English and literary quantifiers\n",
    "        \"many a\", \"such\", \"divers\", \"sundry\", \"manifold\", \"myriad\", \"legion\",\n",
    "        # Distributive quantifiers\n",
    "        \"either\", \"both\", \"half\", \"whole\", \"entire\",\n",
    "        # Indefinite quantifiers\n",
    "        \"certain\", \"various\", \"different\", \"other\", \"another\", \"others\",\n",
    "        \"majority\", \"minority\", \"bulk\", \"rest\",\n",
    "        # Archaic forms\n",
    "        \"nary\", \"naught\", \"aught\", \"ought\", \"whit\",\n",
    "        # Frequency quantifiers\n",
    "        \"always\", \"often\", \"sometimes\", \"rarely\", \"seldom\", \"once\", \"twice\", \"thrice\",\n",
    "        # Common collective terms\n",
    "        \"couple\", \"dozen\", \"score\", \"hundred\", \"thousand\", \"multitude\", \"host\"\n",
    "    ]\n",
    "    \n",
    "    genres_dir = \"../datasets/gutenberg/genres\"\n",
    "    train_files = [f for f in os.listdir(genres_dir) if f.endswith('.train') and '_dev.train' not in f]\n",
    "    \n",
    "    print(f\"Analyzing {len(train_files)} genre datasets...\")\n",
    "    \n",
    "    # Map file names to genres\n",
    "    genre_mapping = {\n",
    "        'mystery': 'Mystery',\n",
    "        'romance': 'Romance', \n",
    "        'sci-fi_fantasy': 'Sci-Fi/Fantasy',\n",
    "        'self_help_non_fiction': 'Self-Help/Non-Fiction',\n",
    "        'youth_and_ya_gutenberg': 'Youth/YA',\n",
    "        'old_english_drama_poetry': 'Old English Drama/Poetry'\n",
    "    }\n",
    "    \n",
    "    file_counts = {}\n",
    "    total_counts = defaultdict(int)\n",
    "    genre_counts = defaultdict(int)\n",
    "    \n",
    "    for file_name in train_files:\n",
    "        file_path = os.path.join(genres_dir, file_name)\n",
    "        \n",
    "        # Determine genre from filename\n",
    "        genre = None\n",
    "        for key, value in genre_mapping.items():\n",
    "            if key in file_name:\n",
    "                genre = value\n",
    "                break\n",
    "        if not genre:\n",
    "            genre = \"Unknown\"\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read().lower()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        file_counts[file_name] = {}\n",
    "        file_total = 0\n",
    "        \n",
    "        for quantifier in quantifiers:\n",
    "            if ' ' in quantifier:\n",
    "                pattern = r'\\b' + re.escape(quantifier.lower()) + r'\\b'\n",
    "            else:\n",
    "                pattern = r'\\b' + re.escape(quantifier.lower()) + r'\\b'\n",
    "            \n",
    "            matches = re.findall(pattern, text)\n",
    "            count = len(matches)\n",
    "            \n",
    "            file_counts[file_name][quantifier] = count\n",
    "            total_counts[quantifier] += count\n",
    "            file_total += count\n",
    "        \n",
    "        genre_counts[genre] += file_total\n",
    "        print(f\"  {file_name}: {file_total:,} quantifiers ({genre})\")\n",
    "    \n",
    "    print(f\"\\nResults by Genre:\")\n",
    "    print(\"-\" * 40)\n",
    "    for genre, total_count in sorted(genre_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{genre:<25}: {total_count:>8,}\")\n",
    "    \n",
    "    grand_total = sum(total_counts.values())\n",
    "    print(f\"\\nGrand Total: {grand_total:,}\")\n",
    "    \n",
    "    return {\n",
    "        'total_counts': dict(total_counts),\n",
    "        'file_counts': file_counts,\n",
    "        'genre_counts': dict(genre_counts),\n",
    "        'grand_total': grand_total\n",
    "    }\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Counting quantifiers in Gutenberg genre datasets...\")\n",
    "results = count_quantifiers_in_gutenberg_genres()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Frequency Analysis by Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting detailed quantifier frequency analysis...\n",
      "QUANTIFIER FREQUENCY ANALYSIS BY GENRE\n",
      "================================================================================\n",
      "Found 6 genre files:\n",
      "  - 1M_mystery_books.train\n",
      "  - 1M_old_english_drama_poetry.train\n",
      "  - 1M_sci-fi_fantasy.train\n",
      "  - 1M_self_help_non_fiction.train\n",
      "  - 1M_romance.train\n",
      "  - 1M_youth_and_ya_gutenberg.train\n",
      "\n",
      "Processing 1M_mystery_books.train -> Mystery...\n",
      "  → Words in this file: 1,000,116\n",
      "  → Quantifiers in this file: 39,282\n",
      "  → Quantifier density: 39.28 per 1000 words\n",
      "\n",
      "Processing 1M_old_english_drama_poetry.train -> Old English Drama/Poetry...\n",
      "  → Words in this file: 1,000,116\n",
      "  → Quantifiers in this file: 39,282\n",
      "  → Quantifier density: 39.28 per 1000 words\n",
      "\n",
      "Processing 1M_old_english_drama_poetry.train -> Old English Drama/Poetry...\n",
      "  → Words in this file: 1,000,251\n",
      "  → Quantifiers in this file: 32,558\n",
      "  → Quantifier density: 32.55 per 1000 words\n",
      "\n",
      "Processing 1M_sci-fi_fantasy.train -> Sci-Fi/Fantasy...\n",
      "  → Words in this file: 1,000,251\n",
      "  → Quantifiers in this file: 32,558\n",
      "  → Quantifier density: 32.55 per 1000 words\n",
      "\n",
      "Processing 1M_sci-fi_fantasy.train -> Sci-Fi/Fantasy...\n",
      "  → Words in this file: 1,000,187\n",
      "  → Quantifiers in this file: 42,419\n",
      "  → Quantifier density: 42.41 per 1000 words\n",
      "\n",
      "Processing 1M_self_help_non_fiction.train -> Self-Help/Non-Fiction...\n",
      "  → Words in this file: 1,000,187\n",
      "  → Quantifiers in this file: 42,419\n",
      "  → Quantifier density: 42.41 per 1000 words\n",
      "\n",
      "Processing 1M_self_help_non_fiction.train -> Self-Help/Non-Fiction...\n",
      "  → Words in this file: 1,000,130\n",
      "  → Quantifiers in this file: 43,521\n",
      "  → Quantifier density: 43.52 per 1000 words\n",
      "\n",
      "Processing 1M_romance.train -> Romance...\n",
      "  → Words in this file: 1,000,130\n",
      "  → Quantifiers in this file: 43,521\n",
      "  → Quantifier density: 43.52 per 1000 words\n",
      "\n",
      "Processing 1M_romance.train -> Romance...\n",
      "  → Words in this file: 1,000,066\n",
      "  → Quantifiers in this file: 47,528\n",
      "  → Quantifier density: 47.52 per 1000 words\n",
      "\n",
      "Processing 1M_youth_and_ya_gutenberg.train -> Youth/YA...\n",
      "  → Words in this file: 1,000,066\n",
      "  → Quantifiers in this file: 47,528\n",
      "  → Quantifier density: 47.52 per 1000 words\n",
      "\n",
      "Processing 1M_youth_and_ya_gutenberg.train -> Youth/YA...\n",
      "  → Words in this file: 1,000,090\n",
      "  → Quantifiers in this file: 46,522\n",
      "  → Quantifier density: 46.52 per 1000 words\n",
      "\n",
      "================================================================================\n",
      "DETAILED FREQUENCY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "1. QUANTIFIER DENSITY BY GENRE\n",
      "--------------------------------------------------\n",
      "Mystery                  :  39.28 quantifiers per 1000 words (39,282 total)\n",
      "Old English Drama/Poetry :  32.55 quantifiers per 1000 words (32,558 total)\n",
      "Romance                  :  47.52 quantifiers per 1000 words (47,528 total)\n",
      "Sci-Fi/Fantasy           :  42.41 quantifiers per 1000 words (42,419 total)\n",
      "Self-Help/Non-Fiction    :  43.52 quantifiers per 1000 words (43,521 total)\n",
      "Youth/YA                 :  46.52 quantifiers per 1000 words (46,522 total)\n",
      "\n",
      "2. TOP 20 QUANTIFIERS ACROSS ALL GENRES\n",
      "------------------------------------------------------------\n",
      " 1. all                 : 27,813\n",
      " 2. no                  : 20,095\n",
      " 3. more                : 12,603\n",
      " 4. any                 : 12,318\n",
      " 5. about               : 10,520\n",
      " 6. some                : 10,509\n",
      " 7. other               :  9,620\n",
      " 8. little              :  9,405\n",
      " 9. such                :  8,593\n",
      "10. much                :  8,008\n",
      "11. never               :  7,431\n",
      "12. over                :  7,078\n",
      "13. most                :  6,409\n",
      "14. every               :  5,543\n",
      "15. nothing             :  5,142\n",
      "16. many                :  4,672\n",
      "17. once                :  4,088\n",
      "18. under               :  4,058\n",
      "19. another             :  3,975\n",
      "20. always              :  3,322\n",
      "\n",
      "3. GENRE-SPECIFIC QUANTIFIER ANALYSIS\n",
      "============================================================\n",
      "\n",
      "MYSTERY:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. no                : 3,689 ( 3.69/1000 words)\n",
      "   2. all               : 3,627 ( 3.63/1000 words)\n",
      "   3. any               : 2,014 ( 2.01/1000 words)\n",
      "   4. about             : 2,006 ( 2.01/1000 words)\n",
      "   5. some              : 1,914 ( 1.91/1000 words)\n",
      "   6. more              : 1,722 ( 1.72/1000 words)\n",
      "   7. little            : 1,564 ( 1.56/1000 words)\n",
      "   8. other             : 1,537 ( 1.54/1000 words)\n",
      "   9. over              : 1,303 ( 1.30/1000 words)\n",
      "  10. much              : 1,108 ( 1.11/1000 words)\n",
      "  11. nothing           :   964 ( 0.96/1000 words)\n",
      "  12. never             :   958 ( 0.96/1000 words)\n",
      "  13. such              :   951 ( 0.95/1000 words)\n",
      "  14. once              :   877 ( 0.88/1000 words)\n",
      "  15. most              :   847 ( 0.85/1000 words)\n",
      "\n",
      "OLD ENGLISH DRAMA/POETRY:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 5,138 ( 5.14/1000 words)\n",
      "   2. no                : 3,429 ( 3.43/1000 words)\n",
      "   3. more              : 2,100 ( 2.10/1000 words)\n",
      "   4. any               : 1,818 ( 1.82/1000 words)\n",
      "   5. such              : 1,700 ( 1.70/1000 words)\n",
      "   6. other             : 1,441 ( 1.44/1000 words)\n",
      "   7. some              : 1,409 ( 1.41/1000 words)\n",
      "   8. most              : 1,256 ( 1.26/1000 words)\n",
      "   9. much              :   928 ( 0.93/1000 words)\n",
      "  10. both              :   871 ( 0.87/1000 words)\n",
      "  11. never             :   863 ( 0.86/1000 words)\n",
      "  12. about             :   768 ( 0.77/1000 words)\n",
      "  13. many              :   707 ( 0.71/1000 words)\n",
      "  14. every             :   583 ( 0.58/1000 words)\n",
      "  15. under             :   536 ( 0.54/1000 words)\n",
      "\n",
      "ROMANCE:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 4,709 ( 4.71/1000 words)\n",
      "   2. no                : 3,997 ( 4.00/1000 words)\n",
      "   3. more              : 2,559 ( 2.56/1000 words)\n",
      "   4. any               : 2,534 ( 2.53/1000 words)\n",
      "   5. such              : 2,236 ( 2.24/1000 words)\n",
      "   6. much              : 1,962 ( 1.96/1000 words)\n",
      "   7. some              : 1,724 ( 1.72/1000 words)\n",
      "   8. never             : 1,638 ( 1.64/1000 words)\n",
      "   9. little            : 1,634 ( 1.63/1000 words)\n",
      "  10. about             : 1,539 ( 1.54/1000 words)\n",
      "  11. other             : 1,534 ( 1.53/1000 words)\n",
      "  12. every             : 1,522 ( 1.52/1000 words)\n",
      "  13. nothing           : 1,280 ( 1.28/1000 words)\n",
      "  14. over              : 1,098 ( 1.10/1000 words)\n",
      "  15. most              : 1,088 ( 1.09/1000 words)\n",
      "\n",
      "SCI-FI/FANTASY:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 4,627 ( 4.63/1000 words)\n",
      "   2. no                : 2,961 ( 2.96/1000 words)\n",
      "   3. about             : 2,248 ( 2.25/1000 words)\n",
      "   4. any               : 2,026 ( 2.03/1000 words)\n",
      "   5. some              : 2,015 ( 2.01/1000 words)\n",
      "   6. little            : 1,820 ( 1.82/1000 words)\n",
      "   7. more              : 1,721 ( 1.72/1000 words)\n",
      "   8. other             : 1,631 ( 1.63/1000 words)\n",
      "   9. over              : 1,557 ( 1.56/1000 words)\n",
      "  10. such              :   956 ( 0.96/1000 words)\n",
      "  11. much              :   938 ( 0.94/1000 words)\n",
      "  12. never             :   886 ( 0.89/1000 words)\n",
      "  13. under             :   861 ( 0.86/1000 words)\n",
      "  14. every             :   818 ( 0.82/1000 words)\n",
      "  15. most              :   803 ( 0.80/1000 words)\n",
      "\n",
      "SELF-HELP/NON-FICTION:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 4,406 ( 4.41/1000 words)\n",
      "   2. no                : 2,799 ( 2.80/1000 words)\n",
      "   3. more              : 2,757 ( 2.76/1000 words)\n",
      "   4. any               : 2,175 ( 2.17/1000 words)\n",
      "   5. other             : 2,068 ( 2.07/1000 words)\n",
      "   6. some              : 1,923 ( 1.92/1000 words)\n",
      "   7. most              : 1,707 ( 1.71/1000 words)\n",
      "   8. much              : 1,619 ( 1.62/1000 words)\n",
      "   9. such              : 1,592 ( 1.59/1000 words)\n",
      "  10. many              : 1,362 ( 1.36/1000 words)\n",
      "  11. never             : 1,206 ( 1.21/1000 words)\n",
      "  12. every             : 1,194 ( 1.19/1000 words)\n",
      "  13. about             : 1,112 ( 1.11/1000 words)\n",
      "  14. little            : 1,014 ( 1.01/1000 words)\n",
      "  15. another           :   901 ( 0.90/1000 words)\n",
      "\n",
      "YOUTH/YA:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 5,306 ( 5.31/1000 words)\n",
      "   2. no                : 3,220 ( 3.22/1000 words)\n",
      "   3. little            : 2,935 ( 2.93/1000 words)\n",
      "   4. about             : 2,847 ( 2.85/1000 words)\n",
      "   5. over              : 2,002 ( 2.00/1000 words)\n",
      "   6. never             : 1,880 ( 1.88/1000 words)\n",
      "   7. any               : 1,751 ( 1.75/1000 words)\n",
      "   8. more              : 1,744 ( 1.74/1000 words)\n",
      "   9. some              : 1,524 ( 1.52/1000 words)\n",
      "  10. much              : 1,453 ( 1.45/1000 words)\n",
      "  11. other             : 1,409 ( 1.41/1000 words)\n",
      "  12. such              : 1,158 ( 1.16/1000 words)\n",
      "  13. a little          :   978 ( 0.98/1000 words)\n",
      "  14. always            :   935 ( 0.93/1000 words)\n",
      "  15. once              :   863 ( 0.86/1000 words)\n",
      "\n",
      "4. QUANTIFIER DISTRIBUTION MATRIX (Top 15 quantifiers)\n",
      "====================================================================================================\n",
      "Quantifier          MysteryOld English      RomanceSci-Fi/FantaSelf-Help/No    Youth/YA     Total\n",
      "----------------------------------------------------------------------------------------------------\n",
      "all                   3,627       5,138       4,709       4,627       4,406       5,306    27,813\n",
      "no                    3,689       3,429       3,997       2,961       2,799       3,220    20,095\n",
      "more                  1,722       2,100       2,559       1,721       2,757       1,744    12,603\n",
      "any                   2,014       1,818       2,534       2,026       2,175       1,751    12,318\n",
      "about                 2,006         768       1,539       2,248       1,112       2,847    10,520\n",
      "some                  1,914       1,409       1,724       2,015       1,923       1,524    10,509\n",
      "other                 1,537       1,441       1,534       1,631       2,068       1,409     9,620\n",
      "little                1,564         438       1,634       1,820       1,014       2,935     9,405\n",
      "such                    951       1,700       2,236         956       1,592       1,158     8,593\n",
      "much                  1,108         928       1,962         938       1,619       1,453     8,008\n",
      "never                   958         863       1,638         886       1,206       1,880     7,431\n",
      "over                  1,303         335       1,098       1,557         783       2,002     7,078\n",
      "most                    847       1,256       1,088         803       1,707         708     6,409\n",
      "every                   589         583       1,522         818       1,194         837     5,543\n",
      "nothing                 964         500       1,280         762         829         807     5,142\n",
      "\n",
      "5. RELATIVE QUANTIFIER PREFERENCES BY GENRE\n",
      "================================================================================\n",
      "\n",
      "Mystery - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  someone           : 2.17x average (  68 times,  0.07/1000)\n",
      "  no less than      : 2.05x average (  14 times,  0.01/1000)\n",
      "  roughly           : 1.84x average (  15 times,  0.01/1000)\n",
      "  various           : 1.60x average ( 121 times,  0.12/1000)\n",
      "  somewhere         : 1.58x average (  75 times,  0.07/1000)\n",
      "  entire            : 1.57x average (  80 times,  0.08/1000)\n",
      "  a few             : 1.57x average ( 475 times,  0.47/1000)\n",
      "  couple            : 1.48x average (  87 times,  0.09/1000)\n",
      "  at most           : 1.44x average (   6 times,  0.01/1000)\n",
      "  few               : 1.44x average ( 625 times,  0.62/1000)\n",
      "\n",
      "Old English Drama/Poetry - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  aught             : 4.46x average (  81 times,  0.08/1000)\n",
      "  thrice            : 4.24x average (  65 times,  0.06/1000)\n",
      "  whit              : 3.92x average (  32 times,  0.03/1000)\n",
      "  naught            : 3.81x average (  61 times,  0.06/1000)\n",
      "  divers            : 3.17x average (  28 times,  0.03/1000)\n",
      "  sundry            : 2.81x average (  22 times,  0.02/1000)\n",
      "  host              : 2.62x average (  82 times,  0.08/1000)\n",
      "  many a            : 2.16x average ( 109 times,  0.11/1000)\n",
      "  none              : 2.07x average ( 444 times,  0.44/1000)\n",
      "  manifold          : 2.00x average (  13 times,  0.01/1000)\n",
      "\n",
      "Romance - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  a great deal of   : 2.21x average (  64 times,  0.06/1000)\n",
      "  nobody            : 2.09x average ( 230 times,  0.23/1000)\n",
      "  ought             : 1.83x average ( 345 times,  0.34/1000)\n",
      "  at least          : 1.75x average ( 269 times,  0.27/1000)\n",
      "  always            : 1.70x average ( 942 times,  0.94/1000)\n",
      "  anybody           : 1.68x average ( 127 times,  0.13/1000)\n",
      "  every             : 1.65x average (1,522 times,  1.52/1000)\n",
      "  such              : 1.56x average (2,236 times,  2.24/1000)\n",
      "  nothing           : 1.49x average (1,280 times,  1.28/1000)\n",
      "  less              : 1.49x average ( 460 times,  0.46/1000)\n",
      "\n",
      "Sci-Fi/Fantasy - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  approximately     : 4.80x average (   4 times,  0.00/1000)\n",
      "  countless         : 4.54x average (  59 times,  0.06/1000)\n",
      "  myriad            : 4.32x average (  18 times,  0.02/1000)\n",
      "  bulk              : 3.29x average (  56 times,  0.06/1000)\n",
      "  fewer than        : 2.73x average (  10 times,  0.01/1000)\n",
      "  multitude         : 2.36x average (  54 times,  0.05/1000)\n",
      "  below             : 2.30x average ( 400 times,  0.40/1000)\n",
      "  a number of       : 2.21x average ( 110 times,  0.11/1000)\n",
      "  dozen             : 2.15x average ( 127 times,  0.13/1000)\n",
      "  hundred           : 2.03x average ( 450 times,  0.45/1000)\n",
      "\n",
      "Self-Help/Non-Fiction - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  fewer than        : 3.27x average (  12 times,  0.01/1000)\n",
      "  majority          : 3.24x average (  53 times,  0.05/1000)\n",
      "  rarely            : 3.05x average (  57 times,  0.06/1000)\n",
      "  minority          : 3.00x average (  12 times,  0.01/1000)\n",
      "  others            : 2.27x average ( 847 times,  0.85/1000)\n",
      "  numerous          : 2.24x average (  74 times,  0.07/1000)\n",
      "  fewer             : 2.22x average (  27 times,  0.03/1000)\n",
      "  divers            : 2.15x average (  19 times,  0.02/1000)\n",
      "  often             : 2.06x average ( 649 times,  0.65/1000)\n",
      "  various           : 2.04x average ( 154 times,  0.15/1000)\n",
      "\n",
      "Youth/YA - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  nary              : 6.00x average (   1 times,  0.00/1000)\n",
      "  lots of           : 4.41x average (  50 times,  0.05/1000)\n",
      "  everyone          : 2.87x average ( 101 times,  0.10/1000)\n",
      "  anybody           : 2.74x average ( 207 times,  0.21/1000)\n",
      "  loads of          : 2.73x average (   5 times,  0.00/1000)\n",
      "  around            : 2.70x average ( 530 times,  0.53/1000)\n",
      "  everybody         : 2.67x average ( 251 times,  0.25/1000)\n",
      "  somebody          : 2.40x average ( 121 times,  0.12/1000)\n",
      "  plenty            : 2.19x average ( 106 times,  0.11/1000)\n",
      "  nobody            : 2.02x average ( 222 times,  0.22/1000)\n",
      "\n",
      "6. ARCHAIC vs MODERN QUANTIFIER USAGE\n",
      "============================================================\n",
      "Archaic quantifier usage by genre:\n",
      "----------------------------------------\n",
      "Mystery                  : Archaic:  0.14/1000, Modern:  2.27/1000\n",
      "Old English Drama/Poetry : Archaic:  0.40/1000, Modern:  0.81/1000\n",
      "Romance                  : Archaic:  0.42/1000, Modern:  1.68/1000\n",
      "Sci-Fi/Fantasy           : Archaic:  0.17/1000, Modern:  2.61/1000\n",
      "Self-Help/Non-Fiction    : Archaic:  0.40/1000, Modern:  1.19/1000\n",
      "Youth/YA                 : Archaic:  0.29/1000, Modern:  3.53/1000\n",
      "  → Words in this file: 1,000,090\n",
      "  → Quantifiers in this file: 46,522\n",
      "  → Quantifier density: 46.52 per 1000 words\n",
      "\n",
      "================================================================================\n",
      "DETAILED FREQUENCY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "1. QUANTIFIER DENSITY BY GENRE\n",
      "--------------------------------------------------\n",
      "Mystery                  :  39.28 quantifiers per 1000 words (39,282 total)\n",
      "Old English Drama/Poetry :  32.55 quantifiers per 1000 words (32,558 total)\n",
      "Romance                  :  47.52 quantifiers per 1000 words (47,528 total)\n",
      "Sci-Fi/Fantasy           :  42.41 quantifiers per 1000 words (42,419 total)\n",
      "Self-Help/Non-Fiction    :  43.52 quantifiers per 1000 words (43,521 total)\n",
      "Youth/YA                 :  46.52 quantifiers per 1000 words (46,522 total)\n",
      "\n",
      "2. TOP 20 QUANTIFIERS ACROSS ALL GENRES\n",
      "------------------------------------------------------------\n",
      " 1. all                 : 27,813\n",
      " 2. no                  : 20,095\n",
      " 3. more                : 12,603\n",
      " 4. any                 : 12,318\n",
      " 5. about               : 10,520\n",
      " 6. some                : 10,509\n",
      " 7. other               :  9,620\n",
      " 8. little              :  9,405\n",
      " 9. such                :  8,593\n",
      "10. much                :  8,008\n",
      "11. never               :  7,431\n",
      "12. over                :  7,078\n",
      "13. most                :  6,409\n",
      "14. every               :  5,543\n",
      "15. nothing             :  5,142\n",
      "16. many                :  4,672\n",
      "17. once                :  4,088\n",
      "18. under               :  4,058\n",
      "19. another             :  3,975\n",
      "20. always              :  3,322\n",
      "\n",
      "3. GENRE-SPECIFIC QUANTIFIER ANALYSIS\n",
      "============================================================\n",
      "\n",
      "MYSTERY:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. no                : 3,689 ( 3.69/1000 words)\n",
      "   2. all               : 3,627 ( 3.63/1000 words)\n",
      "   3. any               : 2,014 ( 2.01/1000 words)\n",
      "   4. about             : 2,006 ( 2.01/1000 words)\n",
      "   5. some              : 1,914 ( 1.91/1000 words)\n",
      "   6. more              : 1,722 ( 1.72/1000 words)\n",
      "   7. little            : 1,564 ( 1.56/1000 words)\n",
      "   8. other             : 1,537 ( 1.54/1000 words)\n",
      "   9. over              : 1,303 ( 1.30/1000 words)\n",
      "  10. much              : 1,108 ( 1.11/1000 words)\n",
      "  11. nothing           :   964 ( 0.96/1000 words)\n",
      "  12. never             :   958 ( 0.96/1000 words)\n",
      "  13. such              :   951 ( 0.95/1000 words)\n",
      "  14. once              :   877 ( 0.88/1000 words)\n",
      "  15. most              :   847 ( 0.85/1000 words)\n",
      "\n",
      "OLD ENGLISH DRAMA/POETRY:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 5,138 ( 5.14/1000 words)\n",
      "   2. no                : 3,429 ( 3.43/1000 words)\n",
      "   3. more              : 2,100 ( 2.10/1000 words)\n",
      "   4. any               : 1,818 ( 1.82/1000 words)\n",
      "   5. such              : 1,700 ( 1.70/1000 words)\n",
      "   6. other             : 1,441 ( 1.44/1000 words)\n",
      "   7. some              : 1,409 ( 1.41/1000 words)\n",
      "   8. most              : 1,256 ( 1.26/1000 words)\n",
      "   9. much              :   928 ( 0.93/1000 words)\n",
      "  10. both              :   871 ( 0.87/1000 words)\n",
      "  11. never             :   863 ( 0.86/1000 words)\n",
      "  12. about             :   768 ( 0.77/1000 words)\n",
      "  13. many              :   707 ( 0.71/1000 words)\n",
      "  14. every             :   583 ( 0.58/1000 words)\n",
      "  15. under             :   536 ( 0.54/1000 words)\n",
      "\n",
      "ROMANCE:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 4,709 ( 4.71/1000 words)\n",
      "   2. no                : 3,997 ( 4.00/1000 words)\n",
      "   3. more              : 2,559 ( 2.56/1000 words)\n",
      "   4. any               : 2,534 ( 2.53/1000 words)\n",
      "   5. such              : 2,236 ( 2.24/1000 words)\n",
      "   6. much              : 1,962 ( 1.96/1000 words)\n",
      "   7. some              : 1,724 ( 1.72/1000 words)\n",
      "   8. never             : 1,638 ( 1.64/1000 words)\n",
      "   9. little            : 1,634 ( 1.63/1000 words)\n",
      "  10. about             : 1,539 ( 1.54/1000 words)\n",
      "  11. other             : 1,534 ( 1.53/1000 words)\n",
      "  12. every             : 1,522 ( 1.52/1000 words)\n",
      "  13. nothing           : 1,280 ( 1.28/1000 words)\n",
      "  14. over              : 1,098 ( 1.10/1000 words)\n",
      "  15. most              : 1,088 ( 1.09/1000 words)\n",
      "\n",
      "SCI-FI/FANTASY:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 4,627 ( 4.63/1000 words)\n",
      "   2. no                : 2,961 ( 2.96/1000 words)\n",
      "   3. about             : 2,248 ( 2.25/1000 words)\n",
      "   4. any               : 2,026 ( 2.03/1000 words)\n",
      "   5. some              : 2,015 ( 2.01/1000 words)\n",
      "   6. little            : 1,820 ( 1.82/1000 words)\n",
      "   7. more              : 1,721 ( 1.72/1000 words)\n",
      "   8. other             : 1,631 ( 1.63/1000 words)\n",
      "   9. over              : 1,557 ( 1.56/1000 words)\n",
      "  10. such              :   956 ( 0.96/1000 words)\n",
      "  11. much              :   938 ( 0.94/1000 words)\n",
      "  12. never             :   886 ( 0.89/1000 words)\n",
      "  13. under             :   861 ( 0.86/1000 words)\n",
      "  14. every             :   818 ( 0.82/1000 words)\n",
      "  15. most              :   803 ( 0.80/1000 words)\n",
      "\n",
      "SELF-HELP/NON-FICTION:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 4,406 ( 4.41/1000 words)\n",
      "   2. no                : 2,799 ( 2.80/1000 words)\n",
      "   3. more              : 2,757 ( 2.76/1000 words)\n",
      "   4. any               : 2,175 ( 2.17/1000 words)\n",
      "   5. other             : 2,068 ( 2.07/1000 words)\n",
      "   6. some              : 1,923 ( 1.92/1000 words)\n",
      "   7. most              : 1,707 ( 1.71/1000 words)\n",
      "   8. much              : 1,619 ( 1.62/1000 words)\n",
      "   9. such              : 1,592 ( 1.59/1000 words)\n",
      "  10. many              : 1,362 ( 1.36/1000 words)\n",
      "  11. never             : 1,206 ( 1.21/1000 words)\n",
      "  12. every             : 1,194 ( 1.19/1000 words)\n",
      "  13. about             : 1,112 ( 1.11/1000 words)\n",
      "  14. little            : 1,014 ( 1.01/1000 words)\n",
      "  15. another           :   901 ( 0.90/1000 words)\n",
      "\n",
      "YOUTH/YA:\n",
      "----------------------------------------\n",
      "Top 15 quantifiers:\n",
      "   1. all               : 5,306 ( 5.31/1000 words)\n",
      "   2. no                : 3,220 ( 3.22/1000 words)\n",
      "   3. little            : 2,935 ( 2.93/1000 words)\n",
      "   4. about             : 2,847 ( 2.85/1000 words)\n",
      "   5. over              : 2,002 ( 2.00/1000 words)\n",
      "   6. never             : 1,880 ( 1.88/1000 words)\n",
      "   7. any               : 1,751 ( 1.75/1000 words)\n",
      "   8. more              : 1,744 ( 1.74/1000 words)\n",
      "   9. some              : 1,524 ( 1.52/1000 words)\n",
      "  10. much              : 1,453 ( 1.45/1000 words)\n",
      "  11. other             : 1,409 ( 1.41/1000 words)\n",
      "  12. such              : 1,158 ( 1.16/1000 words)\n",
      "  13. a little          :   978 ( 0.98/1000 words)\n",
      "  14. always            :   935 ( 0.93/1000 words)\n",
      "  15. once              :   863 ( 0.86/1000 words)\n",
      "\n",
      "4. QUANTIFIER DISTRIBUTION MATRIX (Top 15 quantifiers)\n",
      "====================================================================================================\n",
      "Quantifier          MysteryOld English      RomanceSci-Fi/FantaSelf-Help/No    Youth/YA     Total\n",
      "----------------------------------------------------------------------------------------------------\n",
      "all                   3,627       5,138       4,709       4,627       4,406       5,306    27,813\n",
      "no                    3,689       3,429       3,997       2,961       2,799       3,220    20,095\n",
      "more                  1,722       2,100       2,559       1,721       2,757       1,744    12,603\n",
      "any                   2,014       1,818       2,534       2,026       2,175       1,751    12,318\n",
      "about                 2,006         768       1,539       2,248       1,112       2,847    10,520\n",
      "some                  1,914       1,409       1,724       2,015       1,923       1,524    10,509\n",
      "other                 1,537       1,441       1,534       1,631       2,068       1,409     9,620\n",
      "little                1,564         438       1,634       1,820       1,014       2,935     9,405\n",
      "such                    951       1,700       2,236         956       1,592       1,158     8,593\n",
      "much                  1,108         928       1,962         938       1,619       1,453     8,008\n",
      "never                   958         863       1,638         886       1,206       1,880     7,431\n",
      "over                  1,303         335       1,098       1,557         783       2,002     7,078\n",
      "most                    847       1,256       1,088         803       1,707         708     6,409\n",
      "every                   589         583       1,522         818       1,194         837     5,543\n",
      "nothing                 964         500       1,280         762         829         807     5,142\n",
      "\n",
      "5. RELATIVE QUANTIFIER PREFERENCES BY GENRE\n",
      "================================================================================\n",
      "\n",
      "Mystery - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  someone           : 2.17x average (  68 times,  0.07/1000)\n",
      "  no less than      : 2.05x average (  14 times,  0.01/1000)\n",
      "  roughly           : 1.84x average (  15 times,  0.01/1000)\n",
      "  various           : 1.60x average ( 121 times,  0.12/1000)\n",
      "  somewhere         : 1.58x average (  75 times,  0.07/1000)\n",
      "  entire            : 1.57x average (  80 times,  0.08/1000)\n",
      "  a few             : 1.57x average ( 475 times,  0.47/1000)\n",
      "  couple            : 1.48x average (  87 times,  0.09/1000)\n",
      "  at most           : 1.44x average (   6 times,  0.01/1000)\n",
      "  few               : 1.44x average ( 625 times,  0.62/1000)\n",
      "\n",
      "Old English Drama/Poetry - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  aught             : 4.46x average (  81 times,  0.08/1000)\n",
      "  thrice            : 4.24x average (  65 times,  0.06/1000)\n",
      "  whit              : 3.92x average (  32 times,  0.03/1000)\n",
      "  naught            : 3.81x average (  61 times,  0.06/1000)\n",
      "  divers            : 3.17x average (  28 times,  0.03/1000)\n",
      "  sundry            : 2.81x average (  22 times,  0.02/1000)\n",
      "  host              : 2.62x average (  82 times,  0.08/1000)\n",
      "  many a            : 2.16x average ( 109 times,  0.11/1000)\n",
      "  none              : 2.07x average ( 444 times,  0.44/1000)\n",
      "  manifold          : 2.00x average (  13 times,  0.01/1000)\n",
      "\n",
      "Romance - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  a great deal of   : 2.21x average (  64 times,  0.06/1000)\n",
      "  nobody            : 2.09x average ( 230 times,  0.23/1000)\n",
      "  ought             : 1.83x average ( 345 times,  0.34/1000)\n",
      "  at least          : 1.75x average ( 269 times,  0.27/1000)\n",
      "  always            : 1.70x average ( 942 times,  0.94/1000)\n",
      "  anybody           : 1.68x average ( 127 times,  0.13/1000)\n",
      "  every             : 1.65x average (1,522 times,  1.52/1000)\n",
      "  such              : 1.56x average (2,236 times,  2.24/1000)\n",
      "  nothing           : 1.49x average (1,280 times,  1.28/1000)\n",
      "  less              : 1.49x average ( 460 times,  0.46/1000)\n",
      "\n",
      "Sci-Fi/Fantasy - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  approximately     : 4.80x average (   4 times,  0.00/1000)\n",
      "  countless         : 4.54x average (  59 times,  0.06/1000)\n",
      "  myriad            : 4.32x average (  18 times,  0.02/1000)\n",
      "  bulk              : 3.29x average (  56 times,  0.06/1000)\n",
      "  fewer than        : 2.73x average (  10 times,  0.01/1000)\n",
      "  multitude         : 2.36x average (  54 times,  0.05/1000)\n",
      "  below             : 2.30x average ( 400 times,  0.40/1000)\n",
      "  a number of       : 2.21x average ( 110 times,  0.11/1000)\n",
      "  dozen             : 2.15x average ( 127 times,  0.13/1000)\n",
      "  hundred           : 2.03x average ( 450 times,  0.45/1000)\n",
      "\n",
      "Self-Help/Non-Fiction - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  fewer than        : 3.27x average (  12 times,  0.01/1000)\n",
      "  majority          : 3.24x average (  53 times,  0.05/1000)\n",
      "  rarely            : 3.05x average (  57 times,  0.06/1000)\n",
      "  minority          : 3.00x average (  12 times,  0.01/1000)\n",
      "  others            : 2.27x average ( 847 times,  0.85/1000)\n",
      "  numerous          : 2.24x average (  74 times,  0.07/1000)\n",
      "  fewer             : 2.22x average (  27 times,  0.03/1000)\n",
      "  divers            : 2.15x average (  19 times,  0.02/1000)\n",
      "  often             : 2.06x average ( 649 times,  0.65/1000)\n",
      "  various           : 2.04x average ( 154 times,  0.15/1000)\n",
      "\n",
      "Youth/YA - Most characteristic quantifiers:\n",
      "--------------------------------------------------\n",
      "Quantifiers used MORE than average:\n",
      "  nary              : 6.00x average (   1 times,  0.00/1000)\n",
      "  lots of           : 4.41x average (  50 times,  0.05/1000)\n",
      "  everyone          : 2.87x average ( 101 times,  0.10/1000)\n",
      "  anybody           : 2.74x average ( 207 times,  0.21/1000)\n",
      "  loads of          : 2.73x average (   5 times,  0.00/1000)\n",
      "  around            : 2.70x average ( 530 times,  0.53/1000)\n",
      "  everybody         : 2.67x average ( 251 times,  0.25/1000)\n",
      "  somebody          : 2.40x average ( 121 times,  0.12/1000)\n",
      "  plenty            : 2.19x average ( 106 times,  0.11/1000)\n",
      "  nobody            : 2.02x average ( 222 times,  0.22/1000)\n",
      "\n",
      "6. ARCHAIC vs MODERN QUANTIFIER USAGE\n",
      "============================================================\n",
      "Archaic quantifier usage by genre:\n",
      "----------------------------------------\n",
      "Mystery                  : Archaic:  0.14/1000, Modern:  2.27/1000\n",
      "Old English Drama/Poetry : Archaic:  0.40/1000, Modern:  0.81/1000\n",
      "Romance                  : Archaic:  0.42/1000, Modern:  1.68/1000\n",
      "Sci-Fi/Fantasy           : Archaic:  0.17/1000, Modern:  2.61/1000\n",
      "Self-Help/Non-Fiction    : Archaic:  0.40/1000, Modern:  1.19/1000\n",
      "Youth/YA                 : Archaic:  0.29/1000, Modern:  3.53/1000\n"
     ]
    }
   ],
   "source": [
    "def analyze_quantifier_frequencies_by_genre():\n",
    "    \"\"\"Detailed frequency analysis of quantifiers across genres\"\"\"\n",
    "    \n",
    "    quantifiers = [\n",
    "        \"all\", \"every\", \"each\", \"everyone\", \"everybody\", \"everything\", \"everywhere\",\n",
    "        \"some\", \"any\", \"someone\", \"somebody\", \"something\", \"somewhere\", \n",
    "        \"anyone\", \"anybody\", \"anything\", \"anywhere\",\n",
    "        \"no\", \"none\", \"nothing\", \"nobody\", \"no one\", \"nowhere\", \"neither\", \"never\",\n",
    "        \"most\", \"many\", \"much\", \"few\", \"a few\", \"little\", \"a little\", \"several\",\n",
    "        \"numerous\", \"countless\", \"many a\", \"such\", \"divers\", \"sundry\", \"manifold\", \n",
    "        \"myriad\", \"legion\", \"either\", \"both\", \"half\", \"whole\", \"entire\",\n",
    "        \"certain\", \"various\", \"different\", \"other\", \"another\", \"others\",\n",
    "        \"majority\", \"minority\", \"bulk\", \"rest\", \"nary\", \"naught\", \"aught\", \"ought\", \"whit\",\n",
    "        \"always\", \"often\", \"sometimes\", \"rarely\", \"seldom\", \"once\", \"twice\", \"thrice\",\n",
    "        \"couple\", \"dozen\", \"score\", \"hundred\", \"thousand\", \"multitude\", \"host\"\n",
    "    ]\n",
    "    \n",
    "    genres_dir = \"../datasets/gutenberg/genres\"\n",
    "    train_files = [f for f in os.listdir(genres_dir) if f.endswith('.train') and '_dev.train' not in f]\n",
    "    \n",
    "    genre_mapping = {\n",
    "        'mystery': 'Mystery',\n",
    "        'romance': 'Romance', \n",
    "        'sci-fi_fantasy': 'Sci-Fi/Fantasy',\n",
    "        'self_help_non_fiction': 'Self-Help/Non-Fiction',\n",
    "        'youth_and_ya_gutenberg': 'Youth/YA',\n",
    "        'old_english_drama_poetry': 'Old English Drama/Poetry'\n",
    "    }\n",
    "    \n",
    "    print(\"QUANTIFIER FREQUENCY ANALYSIS BY GENRE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    quantifier_by_genre = defaultdict(lambda: defaultdict(int))\n",
    "    genre_word_counts = {}\n",
    "    genre_quantifier_totals = defaultdict(int)\n",
    "    \n",
    "    # Process each file\n",
    "    for file_name in train_files:\n",
    "        file_path = os.path.join(genres_dir, file_name)\n",
    "        \n",
    "        # Determine genre\n",
    "        genre = None\n",
    "        for key, value in genre_mapping.items():\n",
    "            if key in file_name:\n",
    "                genre = value\n",
    "                break\n",
    "        if not genre:\n",
    "            genre = f\"Unknown ({file_name})\"\n",
    "        \n",
    "        print(f\"Processing {file_name} -> {genre}...\")\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read().lower()\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "            continue\n",
    "        \n",
    "        total_words = len(text.split())\n",
    "        if genre not in genre_word_counts:\n",
    "            genre_word_counts[genre] = 0\n",
    "        genre_word_counts[genre] += total_words\n",
    "        \n",
    "        # Count quantifiers\n",
    "        file_quantifier_total = 0\n",
    "        for quantifier in quantifiers:\n",
    "            if ' ' in quantifier:\n",
    "                pattern = r'\\b' + re.escape(quantifier.lower()) + r'\\b'\n",
    "            else:\n",
    "                pattern = r'\\b' + re.escape(quantifier.lower()) + r'\\b'\n",
    "            \n",
    "            matches = re.findall(pattern, text)\n",
    "            count = len(matches)\n",
    "            quantifier_by_genre[genre][quantifier] += count\n",
    "            file_quantifier_total += count\n",
    "        \n",
    "        genre_quantifier_totals[genre] += file_quantifier_total\n",
    "        density = (file_quantifier_total/total_words)*1000\n",
    "        print(f\"  → {total_words:,} words, {file_quantifier_total:,} quantifiers ({density:.2f}/1000)\")\n",
    "    \n",
    "    # Summary results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"QUANTIFIER DENSITY BY GENRE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for genre in sorted(genre_quantifier_totals.keys()):\n",
    "        total_words = genre_word_counts[genre]\n",
    "        total_quantifiers = genre_quantifier_totals[genre]\n",
    "        density = (total_quantifiers / total_words) * 1000\n",
    "        print(f\"{genre:<25}: {density:>6.2f} per 1000 words ({total_quantifiers:,} total)\")\n",
    "    \n",
    "    # Top quantifiers across all genres\n",
    "    all_quantifier_totals = defaultdict(int)\n",
    "    for genre_data in quantifier_by_genre.values():\n",
    "        for quantifier, count in genre_data.items():\n",
    "            all_quantifier_totals[quantifier] += count\n",
    "    \n",
    "    print(f\"\\nTOP 15 QUANTIFIERS OVERALL:\")\n",
    "    print(\"-\" * 40)\n",
    "    sorted_quantifiers = sorted(all_quantifier_totals.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (quantifier, total_count) in enumerate(sorted_quantifiers[:15], 1):\n",
    "        print(f\"{i:2d}. {quantifier:<15}: {total_count:>6,}\")\n",
    "    \n",
    "    return {\n",
    "        'quantifier_by_genre': dict(quantifier_by_genre),\n",
    "        'genre_word_counts': genre_word_counts,\n",
    "        'genre_quantifier_totals': dict(genre_quantifier_totals),\n",
    "        'all_quantifier_totals': dict(all_quantifier_totals)\n",
    "    }\n",
    "\n",
    "# Run the detailed frequency analysis\n",
    "print(\"Starting quantifier frequency analysis...\")\n",
    "quantifier_freq_results = analyze_quantifier_frequencies_by_genre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive quantifier variety analysis...\n",
      "QUANTIFIER VARIETY & DIVERSITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Analyzing Mystery...\n",
      "--------------------------------------------------\n",
      "Basic Variety:\n",
      "  • Unique quantifiers used: 102\n",
      "  • Total quantifier instances: 39,282\n",
      "  • Average uses per unique quantifier: 385.1\n",
      "Shannon Diversity:\n",
      "  • Shannon Index (H): 3.700\n",
      "  • Shannon Evenness (J): 0.800\n",
      "  • Max possible H for 102 quantifiers: 4.625\n",
      "Simpson Diversity:\n",
      "  • Simpson Index (1-D): 0.962\n",
      "  • Simpson Reciprocal: 26.2\n",
      "Distribution Analysis:\n",
      "  • Most used quantifier: 3689 times\n",
      "  • Least used quantifier: 1 times\n",
      "  • Median usage: 132\n",
      "  • Gini coefficient: 0.700 (0=perfectly equal, 1=maximally unequal)\n",
      "Rare vs Common Quantifiers:\n",
      "  • Rare quantifiers (≤10 uses): 17 (16.7%)\n",
      "  • Common quantifiers (>100 uses): 54 (52.9%)\n",
      "Archaic Quantifier Variety:\n",
      "  • Archaic quantifiers used: 11\n",
      "  • Total archaic instances: 152\n",
      "  • Most used archaic: ought (97 times)\n",
      "\n",
      "Analyzing Old English Drama/Poetry...\n",
      "--------------------------------------------------\n",
      "Basic Variety:\n",
      "  • Unique quantifiers used: 97\n",
      "  • Total quantifier instances: 32,558\n",
      "  • Average uses per unique quantifier: 335.6\n",
      "Shannon Diversity:\n",
      "  • Shannon Index (H): 3.433\n",
      "  • Shannon Evenness (J): 0.750\n",
      "  • Max possible H for 97 quantifiers: 4.575\n",
      "Simpson Diversity:\n",
      "  • Simpson Index (1-D): 0.943\n",
      "  • Simpson Reciprocal: 17.4\n",
      "Distribution Analysis:\n",
      "  • Most used quantifier: 5138 times\n",
      "  • Least used quantifier: 1 times\n",
      "  • Median usage: 78\n",
      "  • Gini coefficient: 0.748 (0=perfectly equal, 1=maximally unequal)\n",
      "Rare vs Common Quantifiers:\n",
      "  • Rare quantifiers (≤10 uses): 15 (15.5%)\n",
      "  • Common quantifiers (>100 uses): 45 (46.4%)\n",
      "Archaic Quantifier Variety:\n",
      "  • Archaic quantifiers used: 10\n",
      "  • Total archaic instances: 470\n",
      "  • Most used archaic: many a (109 times)\n",
      "\n",
      "Analyzing Romance...\n",
      "--------------------------------------------------\n",
      "Basic Variety:\n",
      "  • Unique quantifiers used: 99\n",
      "  • Total quantifier instances: 47,528\n",
      "  • Average uses per unique quantifier: 480.1\n",
      "Shannon Diversity:\n",
      "  • Shannon Index (H): 3.664\n",
      "  • Shannon Evenness (J): 0.797\n",
      "  • Max possible H for 99 quantifiers: 4.595\n",
      "Simpson Diversity:\n",
      "  • Simpson Index (1-D): 0.962\n",
      "  • Simpson Reciprocal: 26.0\n",
      "Distribution Analysis:\n",
      "  • Most used quantifier: 4709 times\n",
      "  • Least used quantifier: 1 times\n",
      "  • Median usage: 154\n",
      "  • Gini coefficient: 0.703 (0=perfectly equal, 1=maximally unequal)\n",
      "Rare vs Common Quantifiers:\n",
      "  • Rare quantifiers (≤10 uses): 17 (17.2%)\n",
      "  • Common quantifiers (>100 uses): 56 (56.6%)\n",
      "Archaic Quantifier Variety:\n",
      "  • Archaic quantifiers used: 10\n",
      "  • Total archaic instances: 426\n",
      "  • Most used archaic: ought (345 times)\n",
      "\n",
      "Analyzing Sci-Fi/Fantasy...\n",
      "--------------------------------------------------\n",
      "Basic Variety:\n",
      "  • Unique quantifiers used: 103\n",
      "  • Total quantifier instances: 42,419\n",
      "  • Average uses per unique quantifier: 411.8\n",
      "Shannon Diversity:\n",
      "  • Shannon Index (H): 3.748\n",
      "  • Shannon Evenness (J): 0.809\n",
      "  • Max possible H for 103 quantifiers: 4.635\n",
      "Simpson Diversity:\n",
      "  • Simpson Index (1-D): 0.963\n",
      "  • Simpson Reciprocal: 27.1\n",
      "Distribution Analysis:\n",
      "  • Most used quantifier: 4627 times\n",
      "  • Least used quantifier: 1 times\n",
      "  • Median usage: 152\n",
      "  • Gini coefficient: 0.686 (0=perfectly equal, 1=maximally unequal)\n",
      "Rare vs Common Quantifiers:\n",
      "  • Rare quantifiers (≤10 uses): 15 (14.6%)\n",
      "  • Common quantifiers (>100 uses): 56 (54.4%)\n",
      "Archaic Quantifier Variety:\n",
      "  • Archaic quantifiers used: 11\n",
      "  • Total archaic instances: 209\n",
      "  • Most used archaic: ought (119 times)\n",
      "\n",
      "Analyzing Self-Help/Non-Fiction...\n",
      "--------------------------------------------------\n",
      "Basic Variety:\n",
      "  • Unique quantifiers used: 101\n",
      "  • Total quantifier instances: 43,521\n",
      "  • Average uses per unique quantifier: 430.9\n",
      "Shannon Diversity:\n",
      "  • Shannon Index (H): 3.696\n",
      "  • Shannon Evenness (J): 0.801\n",
      "  • Max possible H for 101 quantifiers: 4.615\n",
      "Simpson Diversity:\n",
      "  • Simpson Index (1-D): 0.963\n",
      "  • Simpson Reciprocal: 26.9\n",
      "Distribution Analysis:\n",
      "  • Most used quantifier: 4406 times\n",
      "  • Least used quantifier: 2 times\n",
      "  • Median usage: 134\n",
      "  • Gini coefficient: 0.700 (0=perfectly equal, 1=maximally unequal)\n",
      "Rare vs Common Quantifiers:\n",
      "  • Rare quantifiers (≤10 uses): 14 (13.9%)\n",
      "  • Common quantifiers (>100 uses): 52 (51.5%)\n",
      "Archaic Quantifier Variety:\n",
      "  • Archaic quantifiers used: 11\n",
      "  • Total archaic instances: 415\n",
      "  • Most used archaic: ought (279 times)\n",
      "\n",
      "Analyzing Youth/YA...\n",
      "--------------------------------------------------\n",
      "Basic Variety:\n",
      "  • Unique quantifiers used: 99\n",
      "  • Total quantifier instances: 46,522\n",
      "  • Average uses per unique quantifier: 469.9\n",
      "Shannon Diversity:\n",
      "  • Shannon Index (H): 3.657\n",
      "  • Shannon Evenness (J): 0.796\n",
      "  • Max possible H for 99 quantifiers: 4.595\n",
      "Simpson Diversity:\n",
      "  • Simpson Index (1-D): 0.960\n",
      "  • Simpson Reciprocal: 24.9\n",
      "Distribution Analysis:\n",
      "  • Most used quantifier: 5306 times\n",
      "  • Least used quantifier: 1 times\n",
      "  • Median usage: 164\n",
      "  • Gini coefficient: 0.703 (0=perfectly equal, 1=maximally unequal)\n",
      "Rare vs Common Quantifiers:\n",
      "  • Rare quantifiers (≤10 uses): 20 (20.2%)\n",
      "  • Common quantifiers (>100 uses): 59 (59.6%)\n",
      "Archaic Quantifier Variety:\n",
      "  • Archaic quantifiers used: 9\n",
      "  • Total archaic instances: 297\n",
      "  • Most used archaic: ought (239 times)\n",
      "\n",
      "================================================================================\n",
      "COMPARATIVE VARIETY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Number of Unique Quantifiers:\n",
      "------------------------------------------------------------\n",
      "1. Sci-Fi/Fantasy           :    103\n",
      "2. Mystery                  :    102\n",
      "3. Self-Help/Non-Fiction    :    101\n",
      "4. Romance                  :     99\n",
      "5. Youth/YA                 :     99\n",
      "6. Old English Drama/Poetry :     97\n",
      "\n",
      "Shannon Diversity Index:\n",
      "------------------------------------------------------------\n",
      "1. Sci-Fi/Fantasy           :  3.748\n",
      "2. Mystery                  :  3.700\n",
      "3. Self-Help/Non-Fiction    :  3.696\n",
      "4. Romance                  :  3.664\n",
      "5. Youth/YA                 :  3.657\n",
      "6. Old English Drama/Poetry :  3.433\n",
      "\n",
      "Simpson Diversity Index:\n",
      "------------------------------------------------------------\n",
      "1. Sci-Fi/Fantasy           :  0.963\n",
      "2. Self-Help/Non-Fiction    :  0.963\n",
      "3. Mystery                  :  0.962\n",
      "4. Romance                  :  0.962\n",
      "5. Youth/YA                 :  0.960\n",
      "6. Old English Drama/Poetry :  0.943\n",
      "\n",
      "Percentage of Rare Quantifiers:\n",
      "------------------------------------------------------------\n",
      "1. Youth/YA                 :   20.2%\n",
      "2. Romance                  :   17.2%\n",
      "3. Mystery                  :   16.7%\n",
      "4. Old English Drama/Poetry :   15.5%\n",
      "5. Sci-Fi/Fantasy           :   14.6%\n",
      "6. Self-Help/Non-Fiction    :   13.9%\n",
      "\n",
      "Number of Archaic Quantifiers Used:\n",
      "------------------------------------------------------------\n",
      "1. Mystery                  :     11\n",
      "2. Sci-Fi/Fantasy           :     11\n",
      "3. Self-Help/Non-Fiction    :     11\n",
      "4. Old English Drama/Poetry :     10\n",
      "5. Romance                  :     10\n",
      "6. Youth/YA                 :      9\n",
      "\n",
      "Gini Coefficient (Inequality):\n",
      "------------------------------------------------------------\n",
      "1. Sci-Fi/Fantasy           :  0.686\n",
      "2. Mystery                  :  0.700\n",
      "3. Self-Help/Non-Fiction    :  0.700\n",
      "4. Youth/YA                 :  0.703\n",
      "5. Romance                  :  0.703\n",
      "6. Old English Drama/Poetry :  0.748\n",
      "\n",
      "================================================================================\n",
      "FOCUS: OLD ENGLISH DRAMA/POETRY vs OTHER GENRES\n",
      "================================================================================\n",
      "\n",
      "Old English Drama/Poetry Diversity Profile:\n",
      "--------------------------------------------------\n",
      "• Number of Unique Quantifiers: 97 (Rank 6/6)\n",
      "• Shannon Diversity Index: 3.433 (Rank 6/6)\n",
      "• Simpson Diversity Index: 0.943 (Rank 6/6)\n",
      "• Percentage of Rare Quantifiers: 15.5% (Rank 4/6)\n",
      "• Number of Archaic Quantifiers Used: 10 (Rank 4/6)\n",
      "• Gini Coefficient (Inequality): 0.748 (Rank 6/6)\n",
      "\n",
      "Key Insights:\n",
      "--------------------\n",
      "• OLD ENGLISH ranks #6 in quantifier variety\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_quantifier_variety_and_diversity():\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of quantifier variety and diversity across genres.\n",
    "    This will tell us if Old English Drama/Poetry has more diverse quantifier usage.\n",
    "    \"\"\"\n",
    "    print(\"QUANTIFIER VARIETY & DIVERSITY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if 'quantifier_freq_results' not in locals() and 'quantifier_freq_results' not in globals():\n",
    "        print(\"ERROR: quantifier_freq_results not found. Please run the frequency analysis first.\")\n",
    "        return\n",
    "    \n",
    "    results = quantifier_freq_results\n",
    "    \n",
    "    # Data structures for analysis\n",
    "    genre_variety_stats = {}\n",
    "    \n",
    "    for genre in sorted(results['quantifier_by_genre'].keys()):\n",
    "        genre_data = results['quantifier_by_genre'][genre]\n",
    "        total_words = results['genre_word_counts'][genre]\n",
    "        \n",
    "        print(f\"\\nAnalyzing {genre}...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Filter out quantifiers with 0 counts\n",
    "        used_quantifiers = {q: count for q, count in genre_data.items() if count > 0}\n",
    "        \n",
    "        # 1. BASIC VARIETY METRICS\n",
    "        unique_quantifiers = len(used_quantifiers)\n",
    "        total_quantifier_instances = sum(used_quantifiers.values())\n",
    "        \n",
    "        print(f\"Basic Variety:\")\n",
    "        print(f\"  • Unique quantifiers used: {unique_quantifiers}\")\n",
    "        print(f\"  • Total quantifier instances: {total_quantifier_instances:,}\")\n",
    "        print(f\"  • Average uses per unique quantifier: {total_quantifier_instances/unique_quantifiers:.1f}\")\n",
    "        \n",
    "        # 2. SHANNON DIVERSITY INDEX\n",
    "        # H = -Σ(p_i * ln(p_i)) where p_i is proportion of species i\n",
    "        proportions = [count/total_quantifier_instances for count in used_quantifiers.values()]\n",
    "        shannon_diversity = -sum(p * math.log(p) for p in proportions if p > 0)\n",
    "        shannon_evenness = shannon_diversity / math.log(unique_quantifiers) if unique_quantifiers > 1 else 0\n",
    "        \n",
    "        print(f\"Shannon Diversity:\")\n",
    "        print(f\"  • Shannon Index (H): {shannon_diversity:.3f}\")\n",
    "        print(f\"  • Shannon Evenness (J): {shannon_evenness:.3f}\")\n",
    "        print(f\"  • Max possible H for {unique_quantifiers} quantifiers: {math.log(unique_quantifiers):.3f}\")\n",
    "        \n",
    "        # 3. SIMPSON DIVERSITY INDEX\n",
    "        # D = 1 - Σ(p_i^2) - probability that two randomly selected are different\n",
    "        simpson_diversity = 1 - sum(p**2 for p in proportions)\n",
    "        simpson_reciprocal = 1 / sum(p**2 for p in proportions) if sum(p**2 for p in proportions) > 0 else 0\n",
    "        \n",
    "        print(f\"Simpson Diversity:\")\n",
    "        print(f\"  • Simpson Index (1-D): {simpson_diversity:.3f}\")\n",
    "        print(f\"  • Simpson Reciprocal: {simpson_reciprocal:.1f}\")\n",
    "        \n",
    "        # 4. DISTRIBUTION ANALYSIS\n",
    "        counts_list = list(used_quantifiers.values())\n",
    "        counts_list.sort(reverse=True)\n",
    "        \n",
    "        # Gini coefficient (measure of inequality)\n",
    "        n = len(counts_list)\n",
    "        gini = (2 * sum((i + 1) * count for i, count in enumerate(sorted(counts_list)))) / (n * sum(counts_list)) - (n + 1) / n\n",
    "        \n",
    "        print(f\"Distribution Analysis:\")\n",
    "        print(f\"  • Most used quantifier: {max(counts_list)} times\")\n",
    "        print(f\"  • Least used quantifier: {min(counts_list)} times\")\n",
    "        print(f\"  • Median usage: {sorted(counts_list)[len(counts_list)//2]}\")\n",
    "        print(f\"  • Gini coefficient: {gini:.3f} (0=perfectly equal, 1=maximally unequal)\")\n",
    "        \n",
    "        # 5. RARE QUANTIFIERS (used ≤ 10 times)\n",
    "        rare_quantifiers = {q: count for q, count in used_quantifiers.items() if count <= 10}\n",
    "        common_quantifiers = {q: count for q, count in used_quantifiers.items() if count > 100}\n",
    "        \n",
    "        print(f\"Rare vs Common Quantifiers:\")\n",
    "        print(f\"  • Rare quantifiers (≤10 uses): {len(rare_quantifiers)} ({len(rare_quantifiers)/unique_quantifiers*100:.1f}%)\")\n",
    "        print(f\"  • Common quantifiers (>100 uses): {len(common_quantifiers)} ({len(common_quantifiers)/unique_quantifiers*100:.1f}%)\")\n",
    "        \n",
    "        # 6. ARCHAIC QUANTIFIER VARIETY\n",
    "        archaic_quantifiers = [\"ought\", \"aught\", \"naught\", \"whit\", \"nary\", \"divers\", \"sundry\", \"manifold\", \"many a\", \"myriad\", \"legion\", \"thrice\", \"manifold\"]\n",
    "        archaic_used = {q: used_quantifiers.get(q, 0) for q in archaic_quantifiers if used_quantifiers.get(q, 0) > 0}\n",
    "        \n",
    "        print(f\"Archaic Quantifier Variety:\")\n",
    "        print(f\"  • Archaic quantifiers used: {len(archaic_used)}\")\n",
    "        print(f\"  • Total archaic instances: {sum(archaic_used.values())}\")\n",
    "        if archaic_used:\n",
    "            print(f\"  • Most used archaic: {max(archaic_used, key=archaic_used.get)} ({archaic_used[max(archaic_used, key=archaic_used.get)]} times)\")\n",
    "        \n",
    "        # Store results for comparison\n",
    "        genre_variety_stats[genre] = {\n",
    "            'unique_quantifiers': unique_quantifiers,\n",
    "            'total_instances': total_quantifier_instances,\n",
    "            'shannon_diversity': shannon_diversity,\n",
    "            'shannon_evenness': shannon_evenness,\n",
    "            'simpson_diversity': simpson_diversity,\n",
    "            'simpson_reciprocal': simpson_reciprocal,\n",
    "            'gini_coefficient': gini,\n",
    "            'rare_quantifiers': len(rare_quantifiers),\n",
    "            'rare_percentage': len(rare_quantifiers)/unique_quantifiers*100,\n",
    "            'common_quantifiers': len(common_quantifiers),\n",
    "            'archaic_variety': len(archaic_used),\n",
    "            'archaic_instances': sum(archaic_used.values())\n",
    "        }\n",
    "    \n",
    "    # COMPARATIVE ANALYSIS\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARATIVE VARIETY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Sort genres by different diversity metrics\n",
    "    metrics = [\n",
    "        ('unique_quantifiers', 'Number of Unique Quantifiers', False),\n",
    "        ('shannon_diversity', 'Shannon Diversity Index', False),\n",
    "        ('simpson_diversity', 'Simpson Diversity Index', False),\n",
    "        ('rare_percentage', 'Percentage of Rare Quantifiers', False),\n",
    "        ('archaic_variety', 'Number of Archaic Quantifiers Used', False),\n",
    "        ('gini_coefficient', 'Gini Coefficient (Inequality)', True),  # True means lower is better for diversity\n",
    "    ]\n",
    "    \n",
    "    for metric_key, metric_name, reverse_better in metrics:\n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        sorted_genres = sorted(genre_variety_stats.items(), \n",
    "                             key=lambda x: x[1][metric_key], \n",
    "                             reverse=not reverse_better)\n",
    "        \n",
    "        for i, (genre, stats) in enumerate(sorted_genres, 1):\n",
    "            value = stats[metric_key]\n",
    "            if metric_key == 'rare_percentage':\n",
    "                print(f\"{i}. {genre:<25}: {value:>6.1f}%\")\n",
    "            elif 'diversity' in metric_key or 'gini' in metric_key:\n",
    "                print(f\"{i}. {genre:<25}: {value:>6.3f}\")\n",
    "            else:\n",
    "                print(f\"{i}. {genre:<25}: {value:>6}\")\n",
    "    \n",
    "    # SPECIFIC FOCUS ON OLD ENGLISH DRAMA/POETRY\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FOCUS: OLD ENGLISH DRAMA/POETRY vs OTHER GENRES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    old_english = \"Old English Drama/Poetry\"\n",
    "    if old_english in genre_variety_stats:\n",
    "        old_stats = genre_variety_stats[old_english]\n",
    "        \n",
    "        print(f\"\\n{old_english} Diversity Profile:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Calculate rankings\n",
    "        rankings = {}\n",
    "        for metric_key, metric_name, reverse_better in metrics:\n",
    "            sorted_genres = sorted(genre_variety_stats.items(), \n",
    "                                 key=lambda x: x[1][metric_key], \n",
    "                                 reverse=not reverse_better)\n",
    "            for i, (genre, stats) in enumerate(sorted_genres, 1):\n",
    "                if genre == old_english:\n",
    "                    rankings[metric_key] = i\n",
    "                    break\n",
    "        \n",
    "        for metric_key, metric_name, reverse_better in metrics:\n",
    "            rank = rankings[metric_key]\n",
    "            value = old_stats[metric_key]\n",
    "            total_genres = len(genre_variety_stats)\n",
    "            \n",
    "            if metric_key == 'rare_percentage':\n",
    "                print(f\"• {metric_name}: {value:.1f}% (Rank {rank}/{total_genres})\")\n",
    "            elif 'diversity' in metric_key or 'gini' in metric_key:\n",
    "                print(f\"• {metric_name}: {value:.3f} (Rank {rank}/{total_genres})\")\n",
    "            else:\n",
    "                print(f\"• {metric_name}: {value} (Rank {rank}/{total_genres})\")\n",
    "        \n",
    "        # Specific insights\n",
    "        print(f\"\\nKey Insights:\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        if rankings['unique_quantifiers'] == 1:\n",
    "            print(\"✓ OLD ENGLISH has the HIGHEST quantifier variety!\")\n",
    "        elif rankings['unique_quantifiers'] <= 2:\n",
    "            print(\"• OLD ENGLISH has very high quantifier variety (top 2)\")\n",
    "        else:\n",
    "            print(f\"• OLD ENGLISH ranks #{rankings['unique_quantifiers']} in quantifier variety\")\n",
    "        \n",
    "        if rankings['shannon_diversity'] == 1:\n",
    "            print(\"✓ OLD ENGLISH has the most BALANCED quantifier usage!\")\n",
    "        elif rankings['shannon_diversity'] <= 2:\n",
    "            print(\"• OLD ENGLISH has very balanced quantifier usage (top 2)\")\n",
    "            \n",
    "        if rankings['archaic_variety'] == 1:\n",
    "            print(\"✓ OLD ENGLISH uses the most ARCHAIC quantifiers!\")\n",
    "        elif rankings['archaic_variety'] <= 2:\n",
    "            print(\"• OLD ENGLISH has high archaic quantifier usage (top 2)\")\n",
    "    \n",
    "    return genre_variety_stats\n",
    "\n",
    "# Run the comprehensive variety analysis\n",
    "print(\"Starting comprehensive quantifier variety analysis...\")\n",
    "variety_results = analyze_quantifier_variety_and_diversity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Diversity Analysis\n",
    "\n",
    "Analysis using Shannon and Simpson diversity indices to measure quantifier variety across genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 PARADOX ANALYSIS: OLD ENGLISH DRAMA/POETRY MODEL PERFORMANCE\n",
      "================================================================================\n",
      "THE PUZZLE:\n",
      "--------------------\n",
      "• Analysis shows Old English Drama/Poetry ranks LAST in quantifier variety\n",
      "• Yet models trained on it OUTPERFORM others on quantifier tasks\n",
      "• This suggests variety ≠ learnability. Let's investigate why...\n",
      "\n",
      "================================================================================\n",
      "HYPOTHESIS TESTING: What makes Old English Drama/Poetry special for learning?\n",
      "================================================================================\n",
      "\n",
      "1. HYPOTHESIS: DISTINCTIVE USAGE PATTERNS\n",
      "--------------------------------------------------\n",
      "Old English may have fewer quantifiers but use them in more distinctive ways:\n",
      "Quantifiers with DISTINCTIVE usage patterns in Old English (71 found):\n",
      "  • anybody        :  0.01x LESS than others ( 0.00 vs  0.09/1000)\n",
      "  • someone        :  0.03x LESS than others ( 0.00 vs  0.04/1000)\n",
      "  • everybody      :  0.04x LESS than others ( 0.00 vs  0.11/1000)\n",
      "  • around         :  0.04x LESS than others ( 0.01 vs  0.23/1000)\n",
      "  • aught          : 14.46x MORE than others ( 0.08 vs  0.01/1000)\n",
      "  • thrice         : 12.04x MORE than others ( 0.06 vs  0.01/1000)\n",
      "  • a great deal of:  0.09x LESS than others ( 0.00 vs  0.03/1000)\n",
      "  • always         :  0.09x LESS than others ( 0.06 vs  0.65/1000)\n",
      "  • everything     :  0.09x LESS than others ( 0.03 vs  0.29/1000)\n",
      "  • whit           :  9.41x MORE than others ( 0.03 vs  0.00/1000)\n",
      "\n",
      "2. HYPOTHESIS: CONSISTENT STRUCTURAL PATTERNS\n",
      "--------------------------------------------------\n",
      "Old English might have more consistent quantifier usage patterns:\n",
      "• Gini coefficient (inequality): 0.748\n",
      "• Shannon evenness: 0.750\n",
      "\n",
      "Gini coefficient rankings (lower = more consistent):\n",
      "   1. Sci-Fi/Fantasy           : 0.686\n",
      "   2. Mystery                  : 0.700\n",
      "   3. Self-Help/Non-Fiction    : 0.700\n",
      "   4. Youth/YA                 : 0.703\n",
      "   5. Romance                  : 0.703\n",
      "📍 6. Old English Drama/Poetry : 0.748\n",
      "\n",
      "Shannon evenness rankings (higher = more balanced):\n",
      "   1. Sci-Fi/Fantasy           : 0.809\n",
      "   2. Self-Help/Non-Fiction    : 0.801\n",
      "   3. Mystery                  : 0.800\n",
      "   4. Romance                  : 0.797\n",
      "   5. Youth/YA                 : 0.796\n",
      "📍 6. Old English Drama/Poetry : 0.750\n",
      "\n",
      "3. HYPOTHESIS: ARCHAIC QUANTIFIERS = BETTER GRAMMAR\n",
      "--------------------------------------------------\n",
      "Old English uses archaic quantifiers that might teach better grammar:\n",
      "Archaic quantifiers used in Old English:\n",
      "  • many a         :  109 times ( 0.11/1000 words)\n",
      "  • aught          :   81 times ( 0.08/1000 words)\n",
      "  • thrice         :   65 times ( 0.06/1000 words)\n",
      "  • naught         :   61 times ( 0.06/1000 words)\n",
      "  • ought          :   55 times ( 0.05/1000 words)\n",
      "  • whit           :   32 times ( 0.03/1000 words)\n",
      "  • divers         :   28 times ( 0.03/1000 words)\n",
      "  • sundry         :   22 times ( 0.02/1000 words)\n",
      "  • manifold       :   13 times ( 0.01/1000 words)\n",
      "  • legion         :    4 times ( 0.00/1000 words)\n",
      "\n",
      "4. HYPOTHESIS: RICHER SYNTACTIC CONTEXTS\n",
      "--------------------------------------------------\n",
      "Old English Drama/Poetry may provide richer contexts for quantifiers:\n",
      "• Average examples per quantifier: 335.6\n",
      "\n",
      "Context richness rankings (higher = more examples per quantifier):\n",
      "   1. Romance                  :  480.1 examples per unique quantifier\n",
      "   2. Youth/YA                 :  469.9 examples per unique quantifier\n",
      "   3. Self-Help/Non-Fiction    :  430.9 examples per unique quantifier\n",
      "   4. Sci-Fi/Fantasy           :  411.8 examples per unique quantifier\n",
      "   5. Mystery                  :  385.1 examples per unique quantifier\n",
      "📍 6. Old English Drama/Poetry :  335.6 examples per unique quantifier\n",
      "\n",
      "5. HYPOTHESIS: TRAINING EFFICIENCY\n",
      "--------------------------------------------------\n",
      "Old English might be more efficient for learning quantifiers:\n",
      "• Quantifier density: 32.55 per 1000 words\n",
      "• Unique quantifiers: 97\n",
      "• Efficiency ratio (density/variety): 0.336\n",
      "\n",
      "Training efficiency rankings (higher = better density-to-variety ratio):\n",
      "   1. Romance                  : 0.480 (density: 47.52, variety: 99)\n",
      "   2. Youth/YA                 : 0.470 (density: 46.52, variety: 99)\n",
      "   3. Self-Help/Non-Fiction    : 0.431 (density: 43.52, variety: 101)\n",
      "   4. Sci-Fi/Fantasy           : 0.412 (density: 42.41, variety: 103)\n",
      "   5. Mystery                  : 0.385 (density: 39.28, variety: 102)\n",
      "📍 6. Old English Drama/Poetry : 0.336 (density: 32.55, variety: 97)\n",
      "\n",
      "================================================================================\n",
      "🎯 POTENTIAL EXPLANATIONS FOR BETTER MODEL PERFORMANCE\n",
      "================================================================================\n",
      "Old English Drama/Poetry may outperform because it has:\n",
      "✓ 71 quantifiers with DISTINCTIVE usage patterns\n",
      "✓ Uses 10 ARCHAIC quantifiers (formal grammar)\n",
      "\n",
      "📊 KEY INSIGHT:\n",
      "While Old English has the LEAST quantifier variety (97 unique),\n",
      "it may provide HIGHER QUALITY training examples through:\n",
      "  • More consistent and predictable usage patterns\n",
      "  • Distinctive grammatical contexts that generalize well\n",
      "  • Better signal-to-noise ratio for quantifier learning\n",
      "  • Archaic forms that encode explicit grammatical relationships\n",
      "\n",
      "================================================================================\n",
      "CONCLUSION: Quantity ≠ Quality in Language Model Training!\n"
     ]
    }
   ],
   "source": [
    "# PARADOX ANALYSIS: Why does Old English Drama/Poetry train better models despite lower variety?\n",
    "import math\n",
    "\n",
    "print(\"🔍 PARADOX ANALYSIS: OLD ENGLISH DRAMA/POETRY MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"THE PUZZLE:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"• Analysis shows Old English Drama/Poetry ranks LAST in quantifier variety\")\n",
    "print(\"• Yet models trained on it OUTPERFORM others on quantifier tasks\")\n",
    "print(\"• This suggests variety ≠ learnability. Let's investigate why...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPOTHESIS TESTING: What makes Old English Drama/Poetry special for learning?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'quantifier_freq_results' in locals() and 'variety_results' in locals():\n",
    "    old_english = \"Old English Drama/Poetry\"\n",
    "    results = quantifier_freq_results\n",
    "    variety_stats = variety_results\n",
    "    \n",
    "    old_data = results['quantifier_by_genre'][old_english]\n",
    "    old_variety = variety_stats[old_english]\n",
    "    old_words = results['genre_word_counts'][old_english]\n",
    "    \n",
    "    # HYPOTHESIS 1: Quality over Quantity - Distinct Usage Patterns\n",
    "    print(\"\\n1. HYPOTHESIS: DISTINCTIVE USAGE PATTERNS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"Old English may have fewer quantifiers but use them in more distinctive ways:\")\n",
    "    \n",
    "    # Find quantifiers where Old English usage is distinctly different\n",
    "    distinctive_patterns = []\n",
    "    \n",
    "    for quantifier, count in old_data.items():\n",
    "        if count > 0:\n",
    "            old_freq = (count / old_words) * 1000\n",
    "            \n",
    "            # Calculate usage in other genres combined\n",
    "            other_total = sum(results['quantifier_by_genre'][g].get(quantifier, 0) \n",
    "                             for g in results['quantifier_by_genre'].keys() if g != old_english)\n",
    "            other_words = sum(results['genre_word_counts'][g] \n",
    "                             for g in results['genre_word_counts'].keys() if g != old_english)\n",
    "            other_freq = (other_total / other_words) * 1000 if other_words > 0 else 0\n",
    "            \n",
    "            if other_freq > 0:\n",
    "                ratio = old_freq / other_freq\n",
    "                if ratio > 1.5 or ratio < 0.7:  # Significantly different usage\n",
    "                    distinctive_patterns.append((quantifier, count, old_freq, other_freq, ratio))\n",
    "    \n",
    "    distinctive_patterns.sort(key=lambda x: abs(math.log(x[4])), reverse=True)\n",
    "    \n",
    "    print(f\"Quantifiers with DISTINCTIVE usage patterns in Old English ({len(distinctive_patterns)} found):\")\n",
    "    for quantifier, count, old_freq, other_freq, ratio in distinctive_patterns[:10]:\n",
    "        direction = \"MORE\" if ratio > 1 else \"LESS\"\n",
    "        print(f\"  • {quantifier:<15}: {ratio:>5.2f}x {direction} than others ({old_freq:>5.2f} vs {other_freq:>5.2f}/1000)\")\n",
    "    \n",
    "    # HYPOTHESIS 2: Structural Consistency - Lower Variance in Usage\n",
    "    print(\"\\n2. HYPOTHESIS: CONSISTENT STRUCTURAL PATTERNS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"Old English might have more consistent quantifier usage patterns:\")\n",
    "    print(f\"• Gini coefficient (inequality): {old_variety['gini_coefficient']:.3f}\")\n",
    "    print(f\"• Shannon evenness: {old_variety['shannon_evenness']:.3f}\")\n",
    "    \n",
    "    # Compare with other genres\n",
    "    gini_comparison = []\n",
    "    evenness_comparison = []\n",
    "    for genre, stats in variety_stats.items():\n",
    "        gini_comparison.append((genre, stats['gini_coefficient']))\n",
    "        evenness_comparison.append((genre, stats['shannon_evenness']))\n",
    "    \n",
    "    gini_comparison.sort(key=lambda x: x[1])  # Lower Gini = more equal distribution\n",
    "    evenness_comparison.sort(key=lambda x: x[1], reverse=True)  # Higher evenness = better\n",
    "    \n",
    "    print(f\"\\nGini coefficient rankings (lower = more consistent):\")\n",
    "    for i, (genre, gini) in enumerate(gini_comparison, 1):\n",
    "        mark = \"📍\" if genre == old_english else \"  \"\n",
    "        print(f\"{mark} {i}. {genre:<25}: {gini:.3f}\")\n",
    "    \n",
    "    print(f\"\\nShannon evenness rankings (higher = more balanced):\")\n",
    "    for i, (genre, evenness) in enumerate(evenness_comparison, 1):\n",
    "        mark = \"📍\" if genre == old_english else \"  \"\n",
    "        print(f\"{mark} {i}. {genre:<25}: {evenness:.3f}\")\n",
    "    \n",
    "    # HYPOTHESIS 3: Archaic/Formal Quantifiers = Better Grammatical Structure\n",
    "    print(\"\\n3. HYPOTHESIS: ARCHAIC QUANTIFIERS = BETTER GRAMMAR\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    archaic_quantifiers = [\"ought\", \"aught\", \"naught\", \"whit\", \"nary\", \"divers\", \"sundry\", \"manifold\", \"many a\", \"myriad\", \"legion\", \"thrice\"]\n",
    "    \n",
    "    print(\"Old English uses archaic quantifiers that might teach better grammar:\")\n",
    "    \n",
    "    old_archaic_usage = {}\n",
    "    for q in archaic_quantifiers:\n",
    "        if q in old_data and old_data[q] > 0:\n",
    "            old_archaic_usage[q] = old_data[q]\n",
    "    \n",
    "    if old_archaic_usage:\n",
    "        print(\"Archaic quantifiers used in Old English:\")\n",
    "        for q, count in sorted(old_archaic_usage.items(), key=lambda x: x[1], reverse=True):\n",
    "            freq = (count / old_words) * 1000\n",
    "            print(f\"  • {q:<15}: {count:>4} times ({freq:>5.2f}/1000 words)\")\n",
    "    \n",
    "    # HYPOTHESIS 4: Context Quality - Richer Syntactic Contexts\n",
    "    print(\"\\n4. HYPOTHESIS: RICHER SYNTACTIC CONTEXTS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"Old English Drama/Poetry may provide richer contexts for quantifiers:\")\n",
    "    avg_usage = old_variety['total_instances'] / old_variety['unique_quantifiers']\n",
    "    print(f\"• Average examples per quantifier: {avg_usage:.1f}\")\n",
    "    \n",
    "    context_richness = []\n",
    "    for genre, stats in variety_stats.items():\n",
    "        avg = stats['total_instances'] / stats['unique_quantifiers'] if stats['unique_quantifiers'] > 0 else 0\n",
    "        context_richness.append((genre, avg))\n",
    "    \n",
    "    context_richness.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nContext richness rankings (higher = more examples per quantifier):\")\n",
    "    for i, (genre, avg) in enumerate(context_richness, 1):\n",
    "        mark = \"📍\" if genre == old_english else \"  \"\n",
    "        print(f\"{mark} {i}. {genre:<25}: {avg:>6.1f} examples per unique quantifier\")\n",
    "    \n",
    "    # HYPOTHESIS 5: Training Efficiency - Fewer but Better Examples\n",
    "    print(\"\\n5. HYPOTHESIS: TRAINING EFFICIENCY\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(\"Old English might be more efficient for learning quantifiers:\")\n",
    "    density = (old_variety['total_instances']/old_words)*1000\n",
    "    efficiency = density / old_variety['unique_quantifiers']\n",
    "    print(f\"• Quantifier density: {density:.2f} per 1000 words\")\n",
    "    print(f\"• Unique quantifiers: {old_variety['unique_quantifiers']}\")\n",
    "    print(f\"• Efficiency ratio (density/variety): {efficiency:.3f}\")\n",
    "    \n",
    "    efficiency_scores = []\n",
    "    for genre, stats in variety_stats.items():\n",
    "        genre_words = results['genre_word_counts'][genre]\n",
    "        density = (stats['total_instances'] / genre_words) * 1000\n",
    "        efficiency = density / stats['unique_quantifiers']\n",
    "        efficiency_scores.append((genre, efficiency, density, stats['unique_quantifiers']))\n",
    "    \n",
    "    efficiency_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTraining efficiency rankings (higher = better density-to-variety ratio):\")\n",
    "    for i, (genre, eff, density, variety) in enumerate(efficiency_scores, 1):\n",
    "        mark = \"📍\" if genre == old_english else \"  \"\n",
    "        print(f\"{mark} {i}. {genre:<25}: {eff:.3f} (density: {density:.2f}, variety: {variety})\")\n",
    "    \n",
    "    # SUMMARY OF FINDINGS\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🎯 POTENTIAL EXPLANATIONS FOR BETTER MODEL PERFORMANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Calculate Old English's rankings (FIXED: handle tuple structure properly)\n",
    "    old_gini_rank = next(i for i, (g, _) in enumerate(gini_comparison, 1) if g == old_english)\n",
    "    old_evenness_rank = next(i for i, (g, _) in enumerate(evenness_comparison, 1) if g == old_english)\n",
    "    old_context_rank = next(i for i, (g, _) in enumerate(context_richness, 1) if g == old_english)\n",
    "    old_efficiency_rank = next(i for i, item in enumerate(efficiency_scores, 1) if item[0] == old_english)\n",
    "    \n",
    "    explanations = []\n",
    "    \n",
    "    if old_gini_rank <= 2:\n",
    "        explanations.append(f\"✓ More CONSISTENT quantifier usage (Gini rank: #{old_gini_rank}/6)\")\n",
    "    \n",
    "    if old_evenness_rank <= 2:\n",
    "        explanations.append(f\"✓ More BALANCED quantifier distribution (Evenness rank: #{old_evenness_rank}/6)\")\n",
    "    \n",
    "    if old_context_rank <= 2:\n",
    "        explanations.append(f\"✓ RICHER contexts per quantifier (Context rank: #{old_context_rank}/6)\")\n",
    "    \n",
    "    if old_efficiency_rank <= 2:\n",
    "        explanations.append(f\"✓ More EFFICIENT training signal (Efficiency rank: #{old_efficiency_rank}/6)\")\n",
    "    \n",
    "    if len(distinctive_patterns) >= 15:\n",
    "        explanations.append(f\"✓ {len(distinctive_patterns)} quantifiers with DISTINCTIVE usage patterns\")\n",
    "    \n",
    "    if old_variety['archaic_variety'] >= 8:\n",
    "        explanations.append(f\"✓ Uses {old_variety['archaic_variety']} ARCHAIC quantifiers (formal grammar)\")\n",
    "    \n",
    "    print(\"Old English Drama/Poetry may outperform because it has:\")\n",
    "    for explanation in explanations:\n",
    "        print(explanation)\n",
    "    \n",
    "    if not explanations:\n",
    "        print(\"🤔 The basic metrics don't strongly explain the performance difference.\")\n",
    "        print(\"   This suggests more subtle factors may be at play:\")\n",
    "        print(\"   • Quality of syntactic contexts\")\n",
    "        print(\"   • Co-occurrence with other grammatical structures\") \n",
    "        print(\"   • Sentence-level distribution patterns\")\n",
    "    \n",
    "    print(f\"\\n📊 KEY INSIGHT:\")\n",
    "    print(f\"While Old English has the LEAST quantifier variety ({old_variety['unique_quantifiers']} unique),\")\n",
    "    print(f\"it may provide HIGHER QUALITY training examples through:\")\n",
    "    print(f\"  • More consistent and predictable usage patterns\")\n",
    "    print(f\"  • Distinctive grammatical contexts that generalize well\")\n",
    "    print(f\"  • Better signal-to-noise ratio for quantifier learning\")\n",
    "    print(f\"  • Archaic forms that encode explicit grammatical relationships\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Missing analysis results. Please run the quantifier analyses first.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CONCLUSION: Quantity ≠ Quality in Language Model Training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Performance Paradox Analysis\n",
    "\n",
    "Investigation of why **Old English Drama/Poetry** produces superior language models despite having the lowest quantifier variety. The analysis suggests that training data **quality** (consistency, distinctive patterns, rich contexts) may be more important than raw linguistic variety for model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
